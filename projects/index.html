<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> projects | Aswinkumar </title> <meta name="author" content="Aswinkumar "> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/uw.png?e306230ddf8c0af2b014eb173791edae"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://aswinkumar.me/projects/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Aswinkumar</span> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">projects</h1> <p class="post-description"></p> </header> <article> <div class="project-intro"> <p>This page showcases my journey through various projects. The timeline view presents projects chronologically with a central navigation bar, while the grid view organizes projects by organization. Navigate using arrow keys or WASD (↑/W and ↓/S to move between projects, ←/A and →/D to switch views). Click any project to view details in a modal window.</p> </div> <div class="view-switcher-floating"> <div class="switcher-container"> <div class="switcher-slider"></div> <button class="switcher-btn active" data-view="timeline">Timeline</button> <button class="switcher-btn" data-view="grid">Grid</button> </div> </div> <div id="timeline-view" class="view-container"> <div class="projects-timeline"> <div class="timeline-container"> <div class="timeline-filter"> <div class="filter-container"> <div class="filter-slider"></div> <button class="filter-btn" data-filter="software">Software</button> <button class="filter-btn active" data-filter="all">All</button> <button class="filter-btn" data-filter="hardware">Hardware</button> </div> </div> <div id="timeline-bar" style="position: absolute; left: 50%; transform: translateX(-50%); width: 14px; background-color: #696969; border-radius: 10px; z-index: 500;"> <div id="timeline-indicator" style="position: absolute; left: 50%; transform: translateX(-50%); width: 12px; height: 22px; background-color: #FFFFFF; border-radius: 10px; z-index: 9999; box-shadow: 0 0 10px rgba(255, 255, 255, 0.8); border: 1px solid #FFFFFF; pointer-events: none;"></div> </div> <div class="timeline-entries"> <div class="timeline-entry left" data-category="work" style="--org-color: #c5050c;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="wisconsin-ml-project" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> University of Wisconsin-Madison - March 2025 </div> <h3 class="timeline-title">Wisconsin ML Project</h3> <div class="timeline-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/9.jpg" sizes="95vw"></source> <img src="/assets/img/9.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="timeline-desc">Machine learning research conducted at UW-Madison</div> </div> </div> </div> <div id="modal-content-wisconsin-ml-project" style="display: none;"> <div class="modal-header" style="border-color: #c5050c;"> <h2>Wisconsin ML Project</h2> <div class="modal-org" style="color: #c5050c;"> University of Wisconsin-Madison - March 2025 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/9.jpg" sizes="95vw"></source> <img src="/assets/img/9.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Machine learning research conducted at UW-Madison</p> <div class="modal-content"> <p>Every project has a beautiful feature showcase page. It’s easy to include images in a flexible 3-column grid format. Make your photos 1/3, 2/3, or full width.</p> <p>To give your project a background in the portfolio page, just add the img tag to the front matter like so:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
layout: page
title: project
description: a project with a background image
img: /assets/img/12.jpg
---
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1.jpg" sizes="95vw"></source> <img src="/assets/img/1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3.jpg" sizes="95vw"></source> <img src="/assets/img/3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Caption photos easily. On the left, a road goes through a tunnel. Middle, leaves artistically fall in a hipster photoshoot. Right, in another hipster photoshoot, a lumberjack grasps a handful of pine needles. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This image can also have a caption. It's like magic. </div> <p>You can also put regular text between your rows of images. Say you wanted to write a little bit about your project before you posted the rest of the images. You describe how you toiled, sweated, <em>bled</em> for your project, and then… you reveal its glory in the next row of images.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6.jpg" sizes="95vw"></source> <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/11.jpg" sizes="95vw"></source> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> You can also have artistically styled 2/3 + 1/3 images, like these. </div> <p>The code is simple. Just wrap your images with <code class="language-plaintext highlighter-rouge">&lt;div class="col-sm"&gt;</code> and place them inside <code class="language-plaintext highlighter-rouge">&lt;div class="row"&gt;</code> (read more about the <a href="https://getbootstrap.com/docs/4.4/layout/grid/" rel="external nofollow noopener" target="_blank">Bootstrap Grid</a> system). To make images responsive, add <code class="language-plaintext highlighter-rouge">img-fluid</code> class to each; for rounded corners and shadows use <code class="language-plaintext highlighter-rouge">rounded</code> and <code class="language-plaintext highlighter-rouge">z-depth-1</code> classes. Here’s the code for the last row of images above:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"row justify-content-sm-center"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-8 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/6.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-4 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/11.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> </div> </div> </div> </div> <div class="timeline-entry right" data-category="software" style="--org-color: #C5050C;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="mabvit2-model-agnostic-bayesian-vision-transformer" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> University of Wisconsin-Madison - September 2023 </div> <h3 class="timeline-title">MABViT2 - Model Agnostic Bayesian Vision Transformer</h3> <div class="timeline-desc">Novel architecture for vision transformer with uncertainty quantification</div> </div> </div> </div> <div id="modal-content-mabvit2-model-agnostic-bayesian-vision-transformer" style="display: none;"> <div class="modal-header" style="border-color: #C5050C;"> <h2>MABViT2 - Model Agnostic Bayesian Vision Transformer</h2> <div class="modal-org" style="color: #C5050C;"> University of Wisconsin-Madison - September 2023 </div> </div> <div class="modal-description"> <p>Novel architecture for vision transformer with uncertainty quantification</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>Vision Transformers (ViTs) have emerged as powerful models for computer vision tasks but often lack reliable uncertainty quantification. This project addresses this gap by developing MABViT2, a Model Agnostic Bayesian Vision Transformer, enabling uncertainty estimation without architectural modifications.</p> <h1 id="key-contributions">Key Contributions:</h1> <ul> <li>Developed a Bayesian ViT model that quantifies uncertainty without architectural changes</li> <li>Implemented a variational inference approach for parameter estimation</li> <li>Validated performance on benchmark datasets while maintaining competitive accuracy</li> <li>Demonstrated superior out-of-distribution detection compared to deterministic baselines</li> <li>Created a flexible implementation that can be applied to any existing Vision Transformer</li> </ul> <h1 id="technical-details">Technical Details:</h1> <p>The MABViT2 framework uses a Monte Carlo Dropout method in the self-attention mechanism to approximate Bayesian inference. By running multiple forward passes with different dropout masks, the model generates a distribution of predictions that capture epistemic uncertainty. The implementation is compatible with existing ViT architectures like DeiT and ViT-B models.</p> <h1 id="significance">Significance:</h1> <p>This work bridges a critical gap in computer vision by enabling uncertainty quantification in transformer-based models, which is essential for high-stakes applications like medical imaging and autonomous driving. The model-agnostic approach makes it straightforward to apply to existing systems without architectural redesign.</p> </div> </div> </div> </div> <div class="timeline-entry left" data-category="software" style="--org-color: #C5050C;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="vision-language-navigation-with-transformer-architectures" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> University of Wisconsin-Madison - June 2023 </div> <h3 class="timeline-title">Vision-Language Navigation with Transformer Architectures</h3> <div class="timeline-desc">Transformer-based agent for navigating complex environments using natural language instructions</div> </div> </div> </div> <div id="modal-content-vision-language-navigation-with-transformer-architectures" style="display: none;"> <div class="modal-header" style="border-color: #C5050C;"> <h2>Vision-Language Navigation with Transformer Architectures</h2> <div class="modal-org" style="color: #C5050C;"> University of Wisconsin-Madison - June 2023 </div> </div> <div class="modal-description"> <p>Transformer-based agent for navigating complex environments using natural language instructions</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project addresses the challenge of vision-language navigation (VLN), where an agent must navigate to a target location following natural language instructions. The approach uses a transformer-based architecture to integrate visual, linguistic, and spatial information, enabling robust navigation in complex, previously unseen environments.</p> <h1 id="key-contributions">Key Contributions:</h1> <ul> <li>Developed a multi-modal transformer architecture that jointly processes visual and linguistic inputs</li> <li>Implemented a hierarchical planning module that breaks down navigation into macro and micro actions</li> <li>Created a novel attention mechanism that grounds language instructions to visual features</li> <li>Designed a pre-training strategy using a combination of web-scale image-text pairs and navigation data</li> <li>Evaluated the approach on standard VLN benchmarks including R2R, REVERIE, and SOON datasets</li> </ul> <h1 id="technical-implementation">Technical Implementation:</h1> <p>The core architecture consists of:</p> <ol> <li> <p><strong>Visual Encoder</strong>: A vision transformer processes panoramic images at each viewpoint, extracting features at multiple scales.</p> </li> <li> <p><strong>Language Understanding Module</strong>: A language transformer encodes instructions and maintains an attention-based progress monitor.</p> </li> <li> <p><strong>Cross-Modal Reasoning</strong>: A fusion transformer integrates visual and linguistic features, generating a representation that guides navigation decisions.</p> </li> <li> <p><strong>Action Predictor</strong>: A hierarchical decision module that first selects high-level directions and then refines to specific viewpoints.</p> </li> </ol> <p>The model was implemented in PyTorch and trained using a combination of imitation learning and reinforcement learning, with a curriculum that gradually increased the complexity of navigation scenarios.</p> <h1 id="results">Results:</h1> <ul> <li>15% improvement in success rate on the R2R benchmark compared to previous methods</li> <li>12% higher success rate on the REVERIE dataset for object-grounded navigation</li> <li>Effective zero-shot transfer to unseen environments</li> <li>Robust performance with ambiguous and complex language instructions</li> </ul> <p>The project demonstrates the effectiveness of transformer architectures for embodied AI tasks, particularly those requiring multi-modal reasoning and long-horizon planning.</p> </div> </div> </div> </div> <div class="timeline-entry right" data-category="software" style="--org-color: #C5050C;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="robot-action-exploration-using-bayesian-optimization" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> University of Wisconsin-Madison - May 2023 </div> <h3 class="timeline-title">Robot Action Exploration using Bayesian Optimization</h3> <div class="timeline-desc">Novel reinforcement learning approach for efficient robot skill acquisition</div> </div> </div> </div> <div id="modal-content-robot-action-exploration-using-bayesian-optimization" style="display: none;"> <div class="modal-header" style="border-color: #C5050C;"> <h2>Robot Action Exploration using Bayesian Optimization</h2> <div class="modal-org" style="color: #C5050C;"> University of Wisconsin-Madison - May 2023 </div> </div> <div class="modal-description"> <p>Novel reinforcement learning approach for efficient robot skill acquisition</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project addresses the challenge of efficient exploration in robotic manipulation tasks. Traditional reinforcement learning approaches often struggle with the high-dimensional action spaces and sparse rewards common in manipulation tasks. Our approach uses Bayesian optimization to guide exploration in a hierarchical action space, significantly improving learning efficiency.</p> <h1 id="key-contributions">Key Contributions:</h1> <ul> <li>Developed a hierarchical exploration strategy that decomposes complex manipulation tasks into subtasks</li> <li>Implemented a Gaussian Process-based Bayesian optimization framework for efficient action selection</li> <li>Created a directed exploration mechanism based on information gain and expected improvement</li> <li>Designed a task-agnostic representation that generalizes across different manipulation scenarios</li> <li>Evaluated the approach on a range of real-world robotic manipulation tasks</li> </ul> <h1 id="technical-implementation">Technical Implementation:</h1> <p>The framework consists of three main components:</p> <ol> <li> <p><strong>Hierarchical Action Space</strong>: Complex manipulation tasks are represented as sequences of primitive actions organized in a hierarchical structure.</p> </li> <li> <p><strong>Bayesian Optimization</strong>: A Gaussian Process model maintains a belief over the reward function, guiding exploration toward promising regions of the action space.</p> </li> <li> <p><strong>Information-Directed Sampling</strong>: Actions are selected based on a combination of expected reward and information gain, balancing exploration and exploitation.</p> </li> </ol> <p>The system was implemented using PyTorch for the learning components and integrated with ROS for robot control. Experiments were conducted on a 7-DOF robotic arm performing various manipulation tasks.</p> <h1 id="results">Results:</h1> <ul> <li>45% faster skill acquisition compared to standard reinforcement learning approaches</li> <li>Successful learning of complex manipulation tasks with as few as 50 physical trials</li> <li>Effective transfer learning between related tasks</li> <li>Robust performance under varying initial conditions and object properties</li> </ul> <p>The approach demonstrates significant potential for enabling robots to autonomously learn manipulation skills with minimal human supervision, a critical capability for deploying robots in unstructured environments.</p> </div> </div> </div> </div> <div class="timeline-entry left" data-category="hardware" style="--org-color: #c5050c;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="reinforcement-learning-for-hexapod-robot" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> University of Wisconsin-Madison - February 2023 </div> <h3 class="timeline-title">Reinforcement Learning for Hexapod Robot</h3> <div class="timeline-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/hexapod.jpg" sizes="95vw"></source> <img src="/assets/img/project/hexapod.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="timeline-desc">Applying reinforcement learning algorithms to optimize the locomotion of a six-legged robot</div> </div> </div> </div> <div id="modal-content-reinforcement-learning-for-hexapod-robot" style="display: none;"> <div class="modal-header" style="border-color: #c5050c;"> <h2>Reinforcement Learning for Hexapod Robot</h2> <div class="modal-org" style="color: #c5050c;"> University of Wisconsin-Madison - February 2023 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/hexapod.jpg" sizes="95vw"></source> <img src="/assets/img/project/hexapod.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Applying reinforcement learning algorithms to optimize the locomotion of a six-legged robot</p> <div class="modal-content"> <p>Every project has a beautiful feature showcase page. It’s easy to include images in a flexible 3-column grid format. Make your photos 1/3, 2/3, or full width.</p> <p>To give your project a background in the portfolio page, just add the img tag to the front matter like so:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
layout: page
title: project
description: a project with a background image
img: /assets/img/12.jpg
---
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1.jpg" sizes="95vw"></source> <img src="/assets/img/1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3.jpg" sizes="95vw"></source> <img src="/assets/img/3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Caption photos easily. On the left, a road goes through a tunnel. Middle, leaves artistically fall in a hipster photoshoot. Right, in another hipster photoshoot, a lumberjack grasps a handful of pine needles. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This image can also have a caption. It's like magic. </div> <p>You can also put regular text between your rows of images. Say you wanted to write a little bit about your project before you posted the rest of the images. You describe how you toiled, sweated, <em>bled</em> for your project, and then… you reveal its glory in the next row of images.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6.jpg" sizes="95vw"></source> <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/11.jpg" sizes="95vw"></source> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> You can also have artistically styled 2/3 + 1/3 images, like these. </div> <p>The code is simple. Just wrap your images with <code class="language-plaintext highlighter-rouge">&lt;div class="col-sm"&gt;</code> and place them inside <code class="language-plaintext highlighter-rouge">&lt;div class="row"&gt;</code> (read more about the <a href="https://getbootstrap.com/docs/4.4/layout/grid/" rel="external nofollow noopener" target="_blank">Bootstrap Grid</a> system). To make images responsive, add <code class="language-plaintext highlighter-rouge">img-fluid</code> class to each; for rounded corners and shadows use <code class="language-plaintext highlighter-rouge">rounded</code> and <code class="language-plaintext highlighter-rouge">z-depth-1</code> classes. Here’s the code for the last row of images above:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"row justify-content-sm-center"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-8 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/6.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-4 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/11.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> </div> </div> </div> </div> <div class="timeline-entry right" data-category="software" style="--org-color: #76b900;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="cuda-optimized-sparse-matrix-operations" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> NVIDIA - January 2023 </div> <h3 class="timeline-title">CUDA-Optimized Sparse Matrix Operations</h3> <div class="timeline-desc">High-performance matrix operations for ML applications running on NVIDIA GPUs</div> </div> </div> </div> <div id="modal-content-cuda-optimized-sparse-matrix-operations" style="display: none;"> <div class="modal-header" style="border-color: #76b900;"> <h2>CUDA-Optimized Sparse Matrix Operations</h2> <div class="modal-org" style="color: #76b900;"> NVIDIA - January 2023 </div> </div> <div class="modal-description"> <p>High-performance matrix operations for ML applications running on NVIDIA GPUs</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project addresses the computational bottlenecks in deep learning inference by developing optimized CUDA kernels for sparse matrix operations. While GPUs excel at dense computations, many modern neural networks benefit from sparsity, making specialized sparse kernels critical for performance.</p> <h1 id="key-contributions">Key Contributions:</h1> <ul> <li>Developed custom CUDA kernels for sparse matrix-vector multiplication with format-specific optimizations</li> <li>Implemented block-sparse operations tailored for transformer attention mechanisms</li> <li>Created a pruning-aware convolution operator that dynamically adapts to various sparsity patterns</li> <li>Designed memory-efficient sparse matrix storage formats optimized for GPU memory access patterns</li> <li>Integrated the optimized kernels with popular deep learning frameworks like PyTorch and TensorFlow</li> </ul> <h1 id="technical-details">Technical Details:</h1> <p>The implementation leverages advanced CUDA features including shared memory optimization, warp-level primitives, and thread coarsening to maximize throughput. The kernels support various sparsity patterns (structured, unstructured, and block sparsity) with format-specific optimizations.</p> <p>For transformer models, specialized attention mechanism kernels were developed that exploit the inherent sparsity in attention masks. The convolution operators use pruning awareness to dynamically skip computations for zero weights, significantly improving inference speed.</p> <h1 id="performance-results">Performance Results:</h1> <ul> <li>3.8x speedup for sparse matrix-vector multiplication compared to cuSPARSE</li> <li>2.5x faster inference for transformer models with 80% sparsity</li> <li>65% reduction in memory footprint for large language models</li> <li>Linear scaling across multiple GPU configurations</li> </ul> <p>These optimizations enable significant speedups for inference workloads while maintaining model accuracy, making deployment of large-scale models more cost-effective.</p> </div> </div> </div> </div> <div class="timeline-entry left" data-category="software" style="--org-color: #76b900;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="gpu-accelerated-physical-simulation-framework" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> NVIDIA - July 2022 </div> <h3 class="timeline-title">GPU-Accelerated Physical Simulation Framework</h3> <div class="timeline-desc">Parallel physics simulation platform for robotics and graphics applications</div> </div> </div> </div> <div id="modal-content-gpu-accelerated-physical-simulation-framework" style="display: none;"> <div class="modal-header" style="border-color: #76b900;"> <h2>GPU-Accelerated Physical Simulation Framework</h2> <div class="modal-org" style="color: #76b900;"> NVIDIA - July 2022 </div> </div> <div class="modal-description"> <p>Parallel physics simulation platform for robotics and graphics applications</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project addresses the challenge of performing physically accurate simulations of complex environments in real-time. By leveraging GPU acceleration through CUDA, the framework achieves significant performance improvements while maintaining simulation accuracy, enabling applications in robotics, computer graphics, and VR/AR.</p> <h1 id="key-features">Key Features:</h1> <ul> <li>Unified constraint-based physical simulation supporting rigid bodies, soft bodies, and fluids</li> <li>Highly parallel implementation of collision detection and constraint solving</li> <li>Spatial data structures optimized for GPU execution patterns</li> <li>Stable numerical integration methods suitable for interactive applications</li> <li>API compatibility with common robotics and graphics frameworks</li> </ul> <h1 id="technical-implementation">Technical Implementation:</h1> <p>The core of the framework consists of a parallel constraint solver that processes thousands of constraints simultaneously on the GPU. For collision detection, a hierarchical spatial subdivision approach is used to efficiently cull non-colliding pairs of objects. Both broad-phase and narrow-phase collision detection are implemented as parallel algorithms.</p> <p>The framework uses a position-based dynamics approach for soft body simulation, allowing for stable and efficient simulation of deformable objects. Fluid simulation is implemented using a smooth particle hydrodynamics (SPH) method, with neighbor finding accelerated through GPU-optimized spatial hashing.</p> <h1 id="performance-results">Performance Results:</h1> <ul> <li>50-100x speedup over equivalent CPU implementations for rigid body simulation</li> <li>Real-time performance with up to 100,000 rigid bodies or 1 million particles</li> <li>Stable simulation at large time steps, suitable for interactive applications</li> <li>Efficient scaling across different NVIDIA GPU architectures</li> </ul> <h1 id="applications">Applications:</h1> <p>The framework has been successfully applied to robotic simulation for reinforcement learning, real-time physics for game engines, and interactive visualization for scientific applications. Its performance characteristics make it particularly suitable for applications requiring both accuracy and interactivity, such as virtual prototyping and realistic VR environments.</p> </div> </div> </div> </div> <div class="timeline-entry right" data-category="hardware" style="--org-color: #76b900;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="dct-and-idct-hardware-accelerator" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> NVIDIA - May 2022 </div> <h3 class="timeline-title">DCT and IDCT Hardware Accelerator</h3> <div class="timeline-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/IDCT.png" sizes="95vw"></source> <img src="/assets/img/project/IDCT.png" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="timeline-desc">Hardware implementation of Discrete Cosine Transform (DCT) and its inverse for signal processing applications</div> </div> </div> </div> <div id="modal-content-dct-and-idct-hardware-accelerator" style="display: none;"> <div class="modal-header" style="border-color: #76b900;"> <h2>DCT and IDCT Hardware Accelerator</h2> <div class="modal-org" style="color: #76b900;"> NVIDIA - May 2022 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/IDCT.png" sizes="95vw"></source> <img src="/assets/img/project/IDCT.png" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Hardware implementation of Discrete Cosine Transform (DCT) and its inverse for signal processing applications</p> <div class="modal-content"> <p>This project implements a hardware accelerator for Discrete Cosine Transform (DCT) and Inverse Discrete Cosine Transform (IDCT) for signal processing and media applications.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/dct.png" sizes="95vw"></source> <img src="/assets/img/project/dct.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="DCT Diagram" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/IDCT.png" sizes="95vw"></source> <img src="/assets/img/project/IDCT.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="IDCT Diagram" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Left: Flow graph of DCT. Right: Flow graph of IDCT. </div> <h1 id="project-overview">Project Overview:</h1> <p>The core of this work is to implement a hardware accelerator for DCT and IDCT, which are crucial in various signal processing and media applications. With the growth of information technology, the need for efficient compression algorithms has become paramount. DCT has been widely used for several decades due to its incredible energy compaction properties. This project focuses on implementing hardware-level DCT and IDCT transforms for energy-efficient encoding and decoding. The implementation is done using Bluespec, a high-level hardware description language.</p> <h1 id="key-features">Key Features:</h1> <ul> <li>Implementation of Fast DCT algorithm</li> <li>Implementation of IDCT algorithm</li> <li>Modular design for 4-point, 8-point, 16-point, and 32-point transforms</li> <li>Use of Butterfly and Hadamard modules for efficient computation</li> <li>Pipelined architecture for higher throughput</li> <li>The project demonstrates the potential for hardware acceleration in signal processing tasks, particularly in the context of media compression and decompression. It provides a foundation for further optimization and integration into larger systems dealing with video and image processing.</li> </ul> </div> </div> </div> </div> <div class="timeline-entry left" data-category="software" style="--org-color: #231f7e;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="cheetah-soft-robotics-simulator" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> IIT Madras - December 2021 </div> <h3 class="timeline-title">Cheetah Soft Robotics Simulator</h3> <div class="timeline-desc">Simulation platform for soft robots with real-time performance using GPU acceleration</div> </div> </div> </div> <div id="modal-content-cheetah-soft-robotics-simulator" style="display: none;"> <div class="modal-header" style="border-color: #231f7e;"> <h2>Cheetah Soft Robotics Simulator</h2> <div class="modal-org" style="color: #231f7e;"> IIT Madras - December 2021 </div> </div> <div class="modal-description"> <p>Simulation platform for soft robots with real-time performance using GPU acceleration</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project addresses the challenge of efficiently simulating soft and hybrid rigid-soft robots for design and control applications. Inspired by biological systems like cheetahs, which use their flexible spine for enhanced locomotion, the simulator enables exploration of bio-inspired designs that incorporate soft, deformable components alongside traditional rigid elements.</p> <h1 id="key-features">Key Features:</h1> <ul> <li>FEM-based deformation model for accurate simulation of soft materials with varying properties</li> <li>GPU-accelerated parallel solver achieving real-time performance for complex models</li> <li>Unified treatment of rigid and soft body dynamics within a single simulation framework</li> <li>Contact model specifically designed for soft-rigid interactions</li> <li>Open-source implementation with Python and C++ APIs</li> </ul> <h1 id="technical-implementation">Technical Implementation:</h1> <p>The core of the simulator is built on a finite element method (FEM) approach using a corotational formulation for large deformations. To achieve real-time performance, the computational bottleneck of solving large sparse linear systems is addressed through a custom GPU-accelerated preconditioned conjugate gradient solver.</p> <p>The system incorporates a unified constraint-based formulation that handles both soft body deformation and rigid body dynamics, allowing for seamless simulation of hybrid systems. A specialized contact model accounts for the unique challenges of soft material contact, including friction and self-collision.</p> <h1 id="applications">Applications:</h1> <p>The simulator has been applied to several bio-inspired robotic designs, including:</p> <ol> <li> <p><strong>Cheetah-inspired robot</strong>: A quadrupedal robot with a flexible spine, demonstrating how controlled spinal flexibility can enhance running efficiency and maneuverability.</p> </li> <li> <p><strong>Soft grippers</strong>: Simulation of pneumatically actuated soft grippers for delicate object manipulation.</p> </li> <li> <p><strong>Tensegrity robots</strong>: Robots that use a combination of rigid struts and flexible tensile elements for locomotion and adaptation.</p> </li> </ol> <h1 id="impact">Impact:</h1> <p>The simulator enables researchers to explore the design space of soft and hybrid robots more efficiently, testing concepts virtually before physical prototyping. The ability to run simulations in real-time facilitates the development of control algorithms and the application of learning-based approaches to this challenging domain.</p> </div> </div> </div> </div> <div class="timeline-entry right" data-category="software" style="--org-color: #d6a64f;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="carry-save-multiplier-design" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> IIT Madras - September 2021 </div> <h3 class="timeline-title">Carry Save Multiplier Design</h3> <div class="timeline-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/csm.png" sizes="95vw"></source> <img src="/assets/img/project/csm.png" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="timeline-desc">Implementation of an 8x8 carry save multiplier with optimized CMOS design techniques</div> </div> </div> </div> <div id="modal-content-carry-save-multiplier-design" style="display: none;"> <div class="modal-header" style="border-color: #d6a64f;"> <h2>Carry Save Multiplier Design</h2> <div class="modal-org" style="color: #d6a64f;"> IIT Madras - September 2021 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/csm.png" sizes="95vw"></source> <img src="/assets/img/project/csm.png" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Implementation of an 8x8 carry save multiplier with optimized CMOS design techniques</p> <div class="modal-content"> <h1 id="timelapse-of-8-bit-csm">Timelapse of 8-bit CSM</h1> <p>Designed and implemented a compact 8x8 carry save multiplier, leveraging CMOS technology for digital blocks like Inverters, NAND gates, and Full adders, ensuring efficient operation and verification.</p> <p align="center"> <iframe width="560" height="315" src="https://www.youtube.com/embed/wzYCzxJP9SQ?si=eUT2P8DZPsynLZZF" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> </p> </div> </div> </div> </div> <div class="timeline-entry left" data-category="software" style="--org-color: #231f7e;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="custom-compiler-for-mujoco-physics-engine" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> IIT Madras - September 2021 </div> <h3 class="timeline-title">Custom Compiler for MuJoCo Physics Engine</h3> <div class="timeline-desc">Specialized compiler for accelerating physics-based simulation on heterogeneous hardware</div> </div> </div> </div> <div id="modal-content-custom-compiler-for-mujoco-physics-engine" style="display: none;"> <div class="modal-header" style="border-color: #231f7e;"> <h2>Custom Compiler for MuJoCo Physics Engine</h2> <div class="modal-org" style="color: #231f7e;"> IIT Madras - September 2021 </div> </div> <div class="modal-description"> <p>Specialized compiler for accelerating physics-based simulation on heterogeneous hardware</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project addresses the computational bottleneck in physics-based simulation for reinforcement learning and robotics applications. By developing a specialized compiler for MuJoCo physics engine computations, the system achieves significant performance improvements while maintaining simulation accuracy and enabling gradient-based optimization through automatic differentiation.</p> <h1 id="key-contributions">Key Contributions:</h1> <ul> <li>Developed a domain-specific compiler for MuJoCo physics that performs optimizations specific to dynamics simulation</li> <li>Implemented automatic differentiation for the entire simulation pipeline, enabling gradient-based optimization</li> <li>Created a code generator targeting both CPU (with SIMD vectorization) and GPU (CUDA) backends</li> <li>Designed a memory layout optimizer that improves cache locality and reduces memory transfers</li> <li>Integrated the compiler with popular reinforcement learning frameworks like PyTorch and JAX</li> </ul> <h1 id="technical-implementation">Technical Implementation:</h1> <p>The compiler pipeline consists of several stages:</p> <ol> <li> <p><strong>Intermediate Representation</strong>: Physics computations are represented in a domain-specific IR that captures the mathematical structure of dynamics problems.</p> </li> <li> <p><strong>Analysis and Optimization</strong>: The compiler performs graph-based analyses to identify parallelizable computations, redundant calculations, and opportunities for memory optimization.</p> </li> <li> <p><strong>Automatic Differentiation</strong>: The entire simulation pipeline is made differentiable through source code transformation, enabling efficient computation of gradients.</p> </li> <li> <p><strong>Backend Code Generation</strong>: Optimized code is generated for multiple targets including multicore CPUs with SIMD extensions and NVIDIA GPUs via CUDA.</p> </li> </ol> <p>The system supports the full MuJoCo feature set while providing a clean Python API that integrates with machine learning frameworks.</p> <h1 id="performance-results">Performance Results:</h1> <ul> <li>10x average speedup for forward dynamics simulation compared to standard MuJoCo</li> <li>15x faster gradient computation compared to finite-difference methods</li> <li>8x acceleration of reinforcement learning training loops on benchmark tasks</li> <li>Efficient scaling from desktop computers to HPC clusters</li> </ul> <h1 id="applications">Applications:</h1> <p>The compiler has been successfully applied to accelerate reinforcement learning for robotic control, trajectory optimization for legged locomotion, and high-throughput evolutionary algorithms for robot design. The ability to efficiently compute gradients through physics simulations enables new approaches to controller design and system identification problems.</p> </div> </div> </div> </div> <div class="timeline-entry right" data-category="software" style="--org-color: #76b900;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="hardware-accelerated-computer-vision-library" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> NVIDIA - June 2021 </div> <h3 class="timeline-title">Hardware-Accelerated Computer Vision Library</h3> <div class="timeline-desc">Optimized vision algorithms for embedded systems and edge devices</div> </div> </div> </div> <div id="modal-content-hardware-accelerated-computer-vision-library" style="display: none;"> <div class="modal-header" style="border-color: #76b900;"> <h2>Hardware-Accelerated Computer Vision Library</h2> <div class="modal-org" style="color: #76b900;"> NVIDIA - June 2021 </div> </div> <div class="modal-description"> <p>Optimized vision algorithms for embedded systems and edge devices</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project addresses the challenge of deploying computer vision applications on resource-constrained embedded systems and edge devices. By developing hardware-optimized implementations of common vision algorithms and providing a consistent API across different platforms, the library enables efficient vision processing on a wide range of devices.</p> <h1 id="key-features">Key Features:</h1> <ul> <li>Optimized implementations of fundamental vision operations (filtering, feature extraction, optical flow, etc.)</li> <li>Neural network acceleration for deep learning-based vision tasks</li> <li>Hardware-specific optimizations for various platforms (NVIDIA Jetson, Arm processors, DSPs)</li> <li>Automatic selection of optimal implementation based on available hardware</li> <li>Common API across all supported platforms for code portability</li> <li>Comprehensive performance profiling and power monitoring tools</li> <li>Support for both C++ and Python with minimal dependencies</li> </ul> <h1 id="technical-implementation">Technical Implementation:</h1> <p>The library is structured as a layered architecture:</p> <ol> <li> <p><strong>Core API Layer</strong>: Provides a consistent interface for all vision operations, abstracting hardware details from the user.</p> </li> <li> <p><strong>Algorithm Layer</strong>: Implements various vision algorithms with optimizations for numerical stability and accuracy on embedded platforms.</p> </li> <li> <strong>Acceleration Layer</strong>: Contains hardware-specific implementations leveraging various acceleration technologies: <ul> <li>CUDA for NVIDIA GPUs</li> <li>OpenCL for cross-platform GPU acceleration</li> <li>NEON/SVE optimizations for Arm CPUs</li> <li>DSP offloading for supported SoCs</li> <li>Neural accelerator integration (NVDLA, NPU, etc.)</li> </ul> </li> <li> <strong>Platform Layer</strong>: Handles device detection, capability querying, and optimal implementation selection.</li> </ol> <h1 id="performance-results">Performance Results:</h1> <ul> <li>5-20x speedup compared to general-purpose CPU implementations</li> <li>3-8x power efficiency improvement for common vision pipelines</li> <li>Real-time performance for many vision tasks on embedded platforms: <ul> <li>60+ FPS for 1080p image filtering on Jetson Nano</li> <li>30+ FPS for feature detection and tracking on Arm Cortex-A devices</li> <li>15+ FPS for basic neural network inference on low-power microcontrollers</li> </ul> </li> </ul> <h1 id="applications">Applications:</h1> <p>The library has been successfully applied to various edge computing applications:</p> <ul> <li>Smart camera systems for retail analytics</li> <li>Autonomous robot navigation</li> <li>Augmented reality on mobile devices</li> <li>Industrial quality control systems</li> <li>Smart city infrastructure</li> <li>Low-power IoT vision sensors</li> </ul> <p>The project enables developers to leverage computer vision capabilities on constrained devices without requiring expertise in hardware-specific optimization, accelerating the deployment of intelligent edge applications.</p> </div> </div> </div> </div> <div class="timeline-entry left" data-category="software" style="--org-color: #76b900;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="natural-language-processing-for-clinical-data" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> NVIDIA - March 2021 </div> <h3 class="timeline-title">Natural Language Processing for Clinical Data</h3> <div class="timeline-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="timeline-desc">Using NLP techniques to extract insights from medical records</div> </div> </div> </div> <div id="modal-content-natural-language-processing-for-clinical-data" style="display: none;"> <div class="modal-header" style="border-color: #76b900;"> <h2>Natural Language Processing for Clinical Data</h2> <div class="modal-org" style="color: #76b900;"> NVIDIA - March 2021 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Using NLP techniques to extract insights from medical records</p> <div class="modal-content"> <p>Every project has a beautiful feature showcase page. It’s easy to include images in a flexible 3-column grid format. Make your photos 1/3, 2/3, or full width.</p> <p>To give your project a background in the portfolio page, just add the img tag to the front matter like so:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
layout: page
title: project
description: a project with a background image
img: /assets/img/12.jpg
---
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1.jpg" sizes="95vw"></source> <img src="/assets/img/1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3.jpg" sizes="95vw"></source> <img src="/assets/img/3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Caption photos easily. On the left, a road goes through a tunnel. Middle, leaves artistically fall in a hipster photoshoot. Right, in another hipster photoshoot, a lumberjack grasps a handful of pine needles. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This image can also have a caption. It's like magic. </div> <p>You can also put regular text between your rows of images. Say you wanted to write a little bit about your project before you posted the rest of the images. You describe how you toiled, sweated, <em>bled</em> for your project, and then… you reveal its glory in the next row of images.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6.jpg" sizes="95vw"></source> <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/11.jpg" sizes="95vw"></source> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> You can also have artistically styled 2/3 + 1/3 images, like these. </div> <p>The code is simple. Just wrap your images with <code class="language-plaintext highlighter-rouge">&lt;div class="col-sm"&gt;</code> and place them inside <code class="language-plaintext highlighter-rouge">&lt;div class="row"&gt;</code> (read more about the <a href="https://getbootstrap.com/docs/4.4/layout/grid/" rel="external nofollow noopener" target="_blank">Bootstrap Grid</a> system). To make images responsive, add <code class="language-plaintext highlighter-rouge">img-fluid</code> class to each; for rounded corners and shadows use <code class="language-plaintext highlighter-rouge">rounded</code> and <code class="language-plaintext highlighter-rouge">z-depth-1</code> classes. Here’s the code for the last row of images above:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"row justify-content-sm-center"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-8 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/6.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-4 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/11.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> </div> </div> </div> </div> <div class="timeline-entry right" data-category="hardware" style="--org-color: #231f7e;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="autonomous-hexapod-robot" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> IIT Madras - December 2020 </div> <h3 class="timeline-title">Autonomous Hexapod Robot</h3> <div class="timeline-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/hexapod.jpg" sizes="95vw"></source> <img src="/assets/img/project/hexapod.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="timeline-desc">Designed and built a six-legged robot with advanced locomotion capabilities</div> </div> </div> </div> <div id="modal-content-autonomous-hexapod-robot" style="display: none;"> <div class="modal-header" style="border-color: #231f7e;"> <h2>Autonomous Hexapod Robot</h2> <div class="modal-org" style="color: #231f7e;"> IIT Madras - December 2020 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/hexapod.jpg" sizes="95vw"></source> <img src="/assets/img/project/hexapod.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Designed and built a six-legged robot with advanced locomotion capabilities</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project involved designing and constructing a six-legged robot (hexapod) with autonomous capabilities. The hexapod features a distributed control system architecture where each leg has independent control while a central controller coordinates overall movement patterns and stability.</p> <h1 id="key-features">Key Features:</h1> <ul> <li>Six-legged design with 3 degrees of freedom per leg (18 actuated joints total)</li> <li>Custom-designed PCBs for motor control and power distribution</li> <li>Implemented advanced gait generation algorithms for different terrain types</li> <li>Developed a real-time stability management system using accelerometer and gyroscope data</li> <li>Integrated computer vision for obstacle detection and navigation planning</li> <li>Designed a lightweight but durable chassis using 3D-printed components</li> </ul> <h1 id="technical-implementation">Technical Implementation:</h1> <p>The robot uses a hierarchical control system with an ARM Cortex-M4 microcontroller as the main controller and dedicated controllers for each leg. Communication between controllers happens over a custom real-time protocol. The gait generator implements several locomotion patterns including tripod, wave, and ripple gaits that can be switched dynamically based on terrain.</p> <p>A RaspberryPi handles higher-level functions including computer vision through a Pi Camera module, processing images to detect obstacles and plan navigation paths. The power system features lithium polymer batteries with efficient DC-DC conversion to maximize runtime.</p> <h1 id="applications">Applications:</h1> <p>The hexapod platform demonstrates capabilities relevant to search and rescue operations, exploration of hazardous environments, and as an educational platform for robotics research. Its ability to navigate uneven terrain makes it suitable for applications where wheeled robots would struggle.</p> </div> </div> </div> </div> <div class="timeline-entry left" data-category="software" style="--org-color: #231f7e;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="autonomous-uav-navigation-system" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> IIT Madras - August 2020 </div> <h3 class="timeline-title">Autonomous UAV Navigation System</h3> <div class="timeline-desc">Vision-based navigation system for drones operating in GPS-denied environments</div> </div> </div> </div> <div id="modal-content-autonomous-uav-navigation-system" style="display: none;"> <div class="modal-header" style="border-color: #231f7e;"> <h2>Autonomous UAV Navigation System</h2> <div class="modal-org" style="color: #231f7e;"> IIT Madras - August 2020 </div> </div> <div class="modal-description"> <p>Vision-based navigation system for drones operating in GPS-denied environments</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project addresses the challenge of enabling autonomous UAV operation in environments where GPS signals are unavailable or unreliable. By relying solely on onboard sensing and computing, the system provides robust navigation capabilities for applications including search and rescue, infrastructure inspection, and indoor operations.</p> <h1 id="key-features">Key Features:</h1> <ul> <li>Visual-inertial odometry for accurate state estimation without GPS</li> <li>Real-time 3D mapping and simultaneous localization (SLAM)</li> <li>Learning-based obstacle detection and avoidance</li> <li>Path planning with dynamic obstacle handling</li> <li>Fault-tolerant control system with emergency recovery modes</li> <li>Lightweight implementation suitable for deployment on commercial drones</li> <li>Development of a custom simulation environment for testing and validation</li> </ul> <h1 id="technical-implementation">Technical Implementation:</h1> <p>The system consists of four main components:</p> <ol> <li> <p><strong>Perception</strong>: A visual-inertial odometry pipeline fuses data from stereo cameras and an IMU to estimate the drone’s position and orientation. This is complemented by a lightweight SLAM system that builds and maintains a 3D map of the environment.</p> </li> <li> <p><strong>Obstacle Avoidance</strong>: A deep learning-based approach detects obstacles from camera images, while a secondary system uses depth information for obstacle verification. The combined system provides reliable obstacle detection even in challenging lighting conditions.</p> </li> <li> <p><strong>Planning</strong>: A hierarchical planning system combines global path planning using a topological map with local trajectory optimization that accounts for dynamics constraints and obstacle avoidance.</p> </li> <li> <p><strong>Control</strong>: A robust control system translates planned trajectories into motor commands, with adaptive gains to handle different flight conditions and failure modes.</p> </li> </ol> <p>The entire system runs on an NVIDIA Jetson Xavier NX onboard computer, with a custom software stack developed using ROS and optimized for real-time performance.</p> <h1 id="applications-and-results">Applications and Results:</h1> <p>The system has been successfully deployed in several applications:</p> <ul> <li> <strong>Search and Rescue</strong>: Autonomous exploration of disaster sites with detection of victims using thermal imaging</li> <li> <strong>Infrastructure Inspection</strong>: Automated inspection of bridges and buildings with detailed 3D reconstruction</li> <li> <strong>Warehouse Inventory</strong>: Indoor navigation for inventory tracking and management</li> </ul> <p>Performance metrics demonstrate:</p> <ul> <li>Localization accuracy of ±5cm in controlled environments</li> <li>Obstacle detection range of up to 10m with 95% accuracy</li> <li>Successful navigation through complex environments with doorways and corridors</li> <li>Flight endurance of 15 minutes with full autonomy stack active</li> </ul> </div> </div> </div> </div> <div class="timeline-entry right" data-category="hardware" style="--org-color: #d6a64f;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="computer-vision-for-autonomous-systems" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> IIT Madras - July 2020 </div> <h3 class="timeline-title">Computer Vision for Autonomous Systems</h3> <div class="timeline-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1.jpg" sizes="95vw"></source> <img src="/assets/img/1.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="timeline-desc">Developing robust vision systems for self-driving vehicles</div> </div> </div> </div> <div id="modal-content-computer-vision-for-autonomous-systems" style="display: none;"> <div class="modal-header" style="border-color: #d6a64f;"> <h2>Computer Vision for Autonomous Systems</h2> <div class="modal-org" style="color: #d6a64f;"> IIT Madras - July 2020 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1.jpg" sizes="95vw"></source> <img src="/assets/img/1.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Developing robust vision systems for self-driving vehicles</p> <div class="modal-content"> <p>Every project has a beautiful feature showcase page. It’s easy to include images in a flexible 3-column grid format. Make your photos 1/3, 2/3, or full width.</p> <p>To give your project a background in the portfolio page, just add the img tag to the front matter like so:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
layout: page
title: project
description: a project with a background image
img: /assets/img/12.jpg
---
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1.jpg" sizes="95vw"></source> <img src="/assets/img/1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3.jpg" sizes="95vw"></source> <img src="/assets/img/3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Caption photos easily. On the left, a road goes through a tunnel. Middle, leaves artistically fall in a hipster photoshoot. Right, in another hipster photoshoot, a lumberjack grasps a handful of pine needles. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This image can also have a caption. It's like magic. </div> <p>You can also put regular text between your rows of images. Say you wanted to write a little bit about your project before you posted the rest of the images. You describe how you toiled, sweated, <em>bled</em> for your project, and then… you reveal its glory in the next row of images.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6.jpg" sizes="95vw"></source> <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/11.jpg" sizes="95vw"></source> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> You can also have artistically styled 2/3 + 1/3 images, like these. </div> <p>The code is simple. Just wrap your images with <code class="language-plaintext highlighter-rouge">&lt;div class="col-sm"&gt;</code> and place them inside <code class="language-plaintext highlighter-rouge">&lt;div class="row"&gt;</code> (read more about the <a href="https://getbootstrap.com/docs/4.4/layout/grid/" rel="external nofollow noopener" target="_blank">Bootstrap Grid</a> system). To make images responsive, add <code class="language-plaintext highlighter-rouge">img-fluid</code> class to each; for rounded corners and shadows use <code class="language-plaintext highlighter-rouge">rounded</code> and <code class="language-plaintext highlighter-rouge">z-depth-1</code> classes. Here’s the code for the last row of images above:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"row justify-content-sm-center"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-8 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/6.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-4 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/11.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> </div> </div> </div> </div> <div class="timeline-entry left" data-category="software" style="--org-color: #231f7e;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="ai-powered-gta-v-mod-for-autonomous-driving-research" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> IIT Madras - May 2020 </div> <h3 class="timeline-title">AI-Powered GTA V Mod for Autonomous Driving Research</h3> <div class="timeline-desc">Open-source platform for reinforcement learning and computer vision in simulated urban environments</div> </div> </div> </div> <div id="modal-content-ai-powered-gta-v-mod-for-autonomous-driving-research" style="display: none;"> <div class="modal-header" style="border-color: #231f7e;"> <h2>AI-Powered GTA V Mod for Autonomous Driving Research</h2> <div class="modal-org" style="color: #231f7e;"> IIT Madras - May 2020 </div> </div> <div class="modal-description"> <p>Open-source platform for reinforcement learning and computer vision in simulated urban environments</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project addresses the challenge of developing and testing autonomous driving systems by creating a high-fidelity simulation environment based on Grand Theft Auto V. By leveraging the game’s photorealistic graphics, complex physics, and diverse urban environments, the platform enables research on perception, decision-making, and control algorithms for autonomous vehicles.</p> <h1 id="key-features">Key Features:</h1> <ul> <li>Realistic sensor simulation including cameras, LiDAR, radar, and ultrasonic sensors</li> <li>Full access to ground truth data including semantic segmentation, depth maps, and object positions</li> <li>Programmable traffic scenarios with customizable vehicle behaviors</li> <li>Weather and lighting condition control for testing robustness</li> <li>Python API for integration with popular machine learning frameworks</li> <li>Data collection pipeline for creating training datasets</li> <li>Benchmarking suite for comparing different autonomous driving approaches</li> </ul> <h1 id="technical-implementation">Technical Implementation:</h1> <p>The system consists of three main components:</p> <ol> <li> <p><strong>Game Integration</strong>: A native plugin that interfaces with the game engine to extract rendering information, control vehicles, and modify the game environment.</p> </li> <li> <p><strong>Sensor Simulation</strong>: A physics-based simulation layer that generates realistic sensor outputs based on the game state, including camera images with proper distortion, LiDAR point clouds with appropriate noise characteristics, and radar returns.</p> </li> <li> <p><strong>Research Interface</strong>: A Python API that provides access to simulation controls, sensor data, and ground truth information, with built-in support for reinforcement learning environments and computer vision datasets.</p> </li> </ol> <p>The modification was implemented using a combination of C++ for the game integration and Python for the research interface, with optimized data transfer between the two.</p> <h1 id="applications">Applications:</h1> <p>The platform has been used for various autonomous driving research applications:</p> <ul> <li>Training and evaluating perception algorithms in diverse and challenging conditions</li> <li>Developing reinforcement learning agents for urban driving scenarios</li> <li>Benchmarking decision-making algorithms for complex traffic situations</li> <li>Generating synthetic training data for machine learning models</li> <li>Testing edge cases and rare events that are difficult to encounter in real-world testing</li> </ul> <h1 id="impact">Impact:</h1> <p>By providing an accessible, high-fidelity simulation environment, this project helps accelerate autonomous driving research without the high costs and safety concerns associated with real-world testing. The open-source nature of the platform has enabled researchers from various institutions to contribute and build upon the framework.</p> </div> </div> </div> </div> <div class="timeline-entry right" data-category="software" style="--org-color: #d6a64f;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="early-ai-research-project" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> IIT Madras - February 2020 </div> <h3 class="timeline-title">Early AI Research Project</h3> <div class="timeline-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/8.jpg" sizes="95vw"></source> <img src="/assets/img/8.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="timeline-desc">Early exploration of neural networks for pattern recognition</div> </div> </div> </div> <div id="modal-content-early-ai-research-project" style="display: none;"> <div class="modal-header" style="border-color: #d6a64f;"> <h2>Early AI Research Project</h2> <div class="modal-org" style="color: #d6a64f;"> IIT Madras - February 2020 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/8.jpg" sizes="95vw"></source> <img src="/assets/img/8.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Early exploration of neural networks for pattern recognition</p> <div class="modal-content"> <p>Every project has a beautiful feature showcase page. It’s easy to include images in a flexible 3-column grid format. Make your photos 1/3, 2/3, or full width.</p> <p>To give your project a background in the portfolio page, just add the img tag to the front matter like so:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
layout: page
title: project
description: a project with a background image
img: /assets/img/12.jpg
---
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1.jpg" sizes="95vw"></source> <img src="/assets/img/1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3.jpg" sizes="95vw"></source> <img src="/assets/img/3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Caption photos easily. On the left, a road goes through a tunnel. Middle, leaves artistically fall in a hipster photoshoot. Right, in another hipster photoshoot, a lumberjack grasps a handful of pine needles. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This image can also have a caption. It's like magic. </div> <p>You can also put regular text between your rows of images. Say you wanted to write a little bit about your project before you posted the rest of the images. You describe how you toiled, sweated, <em>bled</em> for your project, and then… you reveal its glory in the next row of images.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6.jpg" sizes="95vw"></source> <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/11.jpg" sizes="95vw"></source> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> You can also have artistically styled 2/3 + 1/3 images, like these. </div> <p>The code is simple. Just wrap your images with <code class="language-plaintext highlighter-rouge">&lt;div class="col-sm"&gt;</code> and place them inside <code class="language-plaintext highlighter-rouge">&lt;div class="row"&gt;</code> (read more about the <a href="https://getbootstrap.com/docs/4.4/layout/grid/" rel="external nofollow noopener" target="_blank">Bootstrap Grid</a> system). To make images responsive, add <code class="language-plaintext highlighter-rouge">img-fluid</code> class to each; for rounded corners and shadows use <code class="language-plaintext highlighter-rouge">rounded</code> and <code class="language-plaintext highlighter-rouge">z-depth-1</code> classes. Here’s the code for the last row of images above:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"row justify-content-sm-center"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-8 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/6.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-4 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/11.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> </div> </div> </div> </div> <div class="timeline-entry left" data-category="hardware" style="--org-color: #3fdcbf;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="high-school-project" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> High School - November 2019 </div> <h3 class="timeline-title">High School Project</h3> <div class="timeline-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/4.jpg" sizes="95vw"></source> <img src="/assets/img/4.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="timeline-desc">Project from pre-college years</div> </div> </div> </div> <div id="modal-content-high-school-project" style="display: none;"> <div class="modal-header" style="border-color: #3fdcbf;"> <h2>High School Project</h2> <div class="modal-org" style="color: #3fdcbf;"> High School - November 2019 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/4.jpg" sizes="95vw"></source> <img src="/assets/img/4.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Project from pre-college years</p> <div class="modal-content"> <p>Every project has a beautiful feature showcase page. It’s easy to include images in a flexible 3-column grid format. Make your photos 1/3, 2/3, or full width.</p> <p>To give your project a background in the portfolio page, just add the img tag to the front matter like so:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
layout: page
title: project
description: a project with a background image
img: /assets/img/12.jpg
---
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1.jpg" sizes="95vw"></source> <img src="/assets/img/1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3.jpg" sizes="95vw"></source> <img src="/assets/img/3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Caption photos easily. On the left, a road goes through a tunnel. Middle, leaves artistically fall in a hipster photoshoot. Right, in another hipster photoshoot, a lumberjack grasps a handful of pine needles. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This image can also have a caption. It's like magic. </div> <p>You can also put regular text between your rows of images, even citations (missing reference). Say you wanted to write a bit about your project before you posted the rest of the images. You describe how you toiled, sweated, <em>bled</em> for your project, and then… you reveal its glory in the next row of images.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6.jpg" sizes="95vw"></source> <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/11.jpg" sizes="95vw"></source> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> You can also have artistically styled 2/3 + 1/3 images, like these. </div> <p>The code is simple. Just wrap your images with <code class="language-plaintext highlighter-rouge">&lt;div class="col-sm"&gt;</code> and place them inside <code class="language-plaintext highlighter-rouge">&lt;div class="row"&gt;</code> (read more about the <a href="https://getbootstrap.com/docs/4.4/layout/grid/" rel="external nofollow noopener" target="_blank">Bootstrap Grid</a> system). To make images responsive, add <code class="language-plaintext highlighter-rouge">img-fluid</code> class to each; for rounded corners and shadows use <code class="language-plaintext highlighter-rouge">rounded</code> and <code class="language-plaintext highlighter-rouge">z-depth-1</code> classes. Here’s the code for the last row of images above:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"row justify-content-sm-center"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-8 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/6.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-4 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/11.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> </div> </div> </div> </div> <div class="timeline-entry right" data-category="fun" style="--org-color: #3fdcbf;"> <div class="timeline-dot"></div> <div class="timeline-card-link" data-project-id="robotics-competition-project" onclick="openProjectModal(this)"> <div class="timeline-card"> <div class="timeline-content"> <div class="timeline-date"> High School - May 2018 </div> <h3 class="timeline-title">Robotics Competition Project</h3> <div class="timeline-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6.jpg" sizes="95vw"></source> <img src="/assets/img/6.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="timeline-desc">Award-winning high school robotics project</div> </div> </div> </div> <div id="modal-content-robotics-competition-project" style="display: none;"> <div class="modal-header" style="border-color: #3fdcbf;"> <h2>Robotics Competition Project</h2> <div class="modal-org" style="color: #3fdcbf;"> High School - May 2018 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6.jpg" sizes="95vw"></source> <img src="/assets/img/6.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Award-winning high school robotics project</p> <div class="modal-content"> <p>Every project has a beautiful feature showcase page. It’s easy to include images in a flexible 3-column grid format. Make your photos 1/3, 2/3, or full width.</p> <p>To give your project a background in the portfolio page, just add the img tag to the front matter like so:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
layout: page
title: project
description: a project with a background image
img: /assets/img/12.jpg
---
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1.jpg" sizes="95vw"></source> <img src="/assets/img/1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3.jpg" sizes="95vw"></source> <img src="/assets/img/3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Caption photos easily. On the left, a road goes through a tunnel. Middle, leaves artistically fall in a hipster photoshoot. Right, in another hipster photoshoot, a lumberjack grasps a handful of pine needles. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This image can also have a caption. It's like magic. </div> <p>You can also put regular text between your rows of images. Say you wanted to write a little bit about your project before you posted the rest of the images. You describe how you toiled, sweated, <em>bled</em> for your project, and then… you reveal its glory in the next row of images.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6.jpg" sizes="95vw"></source> <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/11.jpg" sizes="95vw"></source> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> You can also have artistically styled 2/3 + 1/3 images, like these. </div> <p>The code is simple. Just wrap your images with <code class="language-plaintext highlighter-rouge">&lt;div class="col-sm"&gt;</code> and place them inside <code class="language-plaintext highlighter-rouge">&lt;div class="row"&gt;</code> (read more about the <a href="https://getbootstrap.com/docs/4.4/layout/grid/" rel="external nofollow noopener" target="_blank">Bootstrap Grid</a> system). To make images responsive, add <code class="language-plaintext highlighter-rouge">img-fluid</code> class to each; for rounded corners and shadows use <code class="language-plaintext highlighter-rouge">rounded</code> and <code class="language-plaintext highlighter-rouge">z-depth-1</code> classes. Here’s the code for the last row of images above:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"row justify-content-sm-center"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-8 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/6.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-4 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/11.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> </div> </div> </div> </div> </div> </div> <div style="height: 25vh; width: 100%; clear: both;"></div> <script>document.addEventListener("DOMContentLoaded",function(){function t(){console.log("Dots are positioned by CSS with centered alignment")}function e(){const e=Array.from(c).filter(t=>"none"!==t.style.display);if(e.length>0){t();const i=e[0],o=e[e.length-1],l=i.querySelector(".timeline-dot"),c=o.querySelector(".timeline-dot");window.innerWidth;if(l&&c){const t=i.getBoundingClientRect(),e=o.getBoundingClientRect(),l=document.querySelector(".timeline-container").getBoundingClientRect(),c=22,s=t.height/2,r=(e.height,window.innerHeight,s-1.25*c),d=t.top-l.top+r,a=e.top-l.top+e.height/2-c/2-d;n.style.top=`${d}px`,n.style.height=`${a}px`,console.log("Timeline bar positioned with fixed offsets",{top:d,height:a})}else{const t=i.getBoundingClientRect(),e=o.getBoundingClientRect(),l=document.querySelector(".timeline-container").getBoundingClientRect(),c=22,s=t.height/2,r=(e.height,s-c),d=t.top-l.top+r,a=e.top-l.top+e.height/2-c/2-d;n.style.top=`${d}px`,n.style.height=`${a}px`}}}const n=document.getElementById("timeline-bar"),i=document.getElementById("timeline-indicator"),o=document.querySelectorAll(".filter-btn"),l=document.querySelector(".filter-slider"),c=document.querySelectorAll(".timeline-entry");o.forEach((t,e)=>{t.addEventListener("click",function(){o.forEach(t=>t.classList.remove("active")),this.classList.add("active");const t=100/o.length;l.style.left=`calc(${t*e}% + 6px)`,l.style.width=`calc(${t}% - 12px)`;const i=this.getAttribute("data-filter");console.log("Filter selected:",i),c.forEach(t=>{t.style.opacity="0"}),setTimeout(()=>{c.forEach(t=>{const e=t.getAttribute("data-category");t.style.display="all"===i||e===i?"":"none"});const t=Array.from(c).filter(t=>"none"!==t.style.display);t.forEach((t,e)=>{t.classList.remove("left","right"),t.classList.add(e%2==0?"left":"right");const n=t.querySelector(".timeline-dot");if(n){const t=e%2==0;n.style.left=t?"":"-8px",n.style.right=t?"-8px":""}}),setTimeout(()=>{t.forEach(t=>{t.style.opacity=""}),setTimeout(()=>{const t=Array.from(c).filter(t=>"none"!==t.style.display);if(document.body.offsetHeight,t.length>0){const e=t[0],i=t[t.length-1],o=document.querySelector(".timeline-container").getBoundingClientRect(),l=e.querySelector(".timeline-dot"),c=i.querySelector(".timeline-dot");if(l&&c){l.getBoundingClientRect(),c.getBoundingClientRect();const t=22,s=e.getBoundingClientRect(),r=i.getBoundingClientRect(),d=s.height/2,a=(r.height,window.innerHeight,d-t/2-25+25-11),h=s.top-o.top+a,g=r.top-o.top+r.height/2-t/2-h;n.style.top=`${h}px`,n.style.height=`${g}px`,console.log("Timeline bar positioned after filter with consistent logic",{top:h,height:g})}}},200)},100)},300)})});let s=null,r=!1;window.addEventListener("scroll",function(){if(!i||!n)return;const t=window.innerHeight,e=t/2,o=n.getBoundingClientRect(),l=(document.querySelector(".timeline-container").getBoundingClientRect(),window.innerWidth,Math.max(0,Math.min(1,(e-o.top)/o.height))),d=o.height*l;d<0?i.style.top="0px":d>o.height-22?i.style.top=o.height-22+"px":i.style.top=d+"px";const a=Array.from(c).filter(t=>"none"!==t.style.display);let h=null,g=Infinity;a.forEach(t=>{const n=t.getBoundingClientRect(),i=n.top+n.height/2,o=Math.abs(e-i);o<g&&(g=o,h=t)}),h&&(c.forEach(t=>t.classList.remove("active")),h.classList.add("active"),r=!0,s&&clearTimeout(s),s=setTimeout(function(){if(r=!1,g<150){const e=h.getBoundingClientRect(),n=h.querySelector(".timeline-dot");if(n){const e=n.getBoundingClientRect().top,i=-10,o=window.scrollY+e-t/2+i;window.scrollTo({top:o,behavior:"smooth"}),console.log("Snapping with offset",{dotTop:e,visualOffset:i,targetY:o})}else{const n=window.scrollY+e.top+e.height/2-t/2;window.scrollTo({top:n,behavior:"smooth"})}}},500))});const d=Array.from(o).findIndex(t=>t.classList.contains("active"));if(-1!==d){const t=100/o.length;l.style.left=`calc(${t*d}% + 6px)`,l.style.width=`calc(${t}% - 12px)`}window.addEventListener("load",function(){const t=function(){window.innerWidth<=768?(n.style.left="20px",n.style.transform="none",i.style.left="50%",i.style.transform="translateX(-50%)"):(n.style.left="50%",n.style.transform="translateX(-50%)",i.style.left="50%",i.style.transform="translateX(-50%)")};t(),window.addEventListener("resize",t),e(),window.dispatchEvent(new Event("scroll"))}),window.addEventListener("resize",function(){t()}),document.querySelectorAll(".github-link").forEach(t=>{t.addEventListener("click",function(t){t.stopPropagation()})})});</script> </div> </div> <div id="grid-view" class="view-container" style="display: none;"> <div class="projects"> <a id="university-of-wisconsin-madison" href=".#university-of-wisconsin-madison"> <h2 class="category" style="color: #c5050c;">University of Wisconsin-Madison</h2> </a> <div class="row row-cols-2 row-cols-md-4"> <div class="col"> <div class="grid-card-wrapper" data-project-id="wisconsin-ml-project" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/9.jpg" sizes="200px"></source> <img src="/assets/img/9.jpg" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #c5050c;"> University of Wisconsin-Madison </div> <h3 class="card-title">Wisconsin ML Project</h3> <p class="card-text small">Machine learning research conducted at UW-Madison</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-wisconsin-ml-project" style="display: none;"> <div class="modal-header" style="border-color: #c5050c;"> <h2>Wisconsin ML Project</h2> <div class="modal-org" style="color: #c5050c;"> University of Wisconsin-Madison - March 2025 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/9.jpg" sizes="95vw"></source> <img src="/assets/img/9.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Machine learning research conducted at UW-Madison</p> <div class="modal-content"> <p>Every project has a beautiful feature showcase page. It’s easy to include images in a flexible 3-column grid format. Make your photos 1/3, 2/3, or full width.</p> <p>To give your project a background in the portfolio page, just add the img tag to the front matter like so:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
layout: page
title: project
description: a project with a background image
img: /assets/img/12.jpg
---
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1.jpg" sizes="95vw"></source> <img src="/assets/img/1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3.jpg" sizes="95vw"></source> <img src="/assets/img/3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Caption photos easily. On the left, a road goes through a tunnel. Middle, leaves artistically fall in a hipster photoshoot. Right, in another hipster photoshoot, a lumberjack grasps a handful of pine needles. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This image can also have a caption. It's like magic. </div> <p>You can also put regular text between your rows of images. Say you wanted to write a little bit about your project before you posted the rest of the images. You describe how you toiled, sweated, <em>bled</em> for your project, and then… you reveal its glory in the next row of images.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6.jpg" sizes="95vw"></source> <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/11.jpg" sizes="95vw"></source> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> You can also have artistically styled 2/3 + 1/3 images, like these. </div> <p>The code is simple. Just wrap your images with <code class="language-plaintext highlighter-rouge">&lt;div class="col-sm"&gt;</code> and place them inside <code class="language-plaintext highlighter-rouge">&lt;div class="row"&gt;</code> (read more about the <a href="https://getbootstrap.com/docs/4.4/layout/grid/" rel="external nofollow noopener" target="_blank">Bootstrap Grid</a> system). To make images responsive, add <code class="language-plaintext highlighter-rouge">img-fluid</code> class to each; for rounded corners and shadows use <code class="language-plaintext highlighter-rouge">rounded</code> and <code class="language-plaintext highlighter-rouge">z-depth-1</code> classes. Here’s the code for the last row of images above:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"row justify-content-sm-center"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-8 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/6.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-4 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/11.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> </div> </div> </div> </div> <div class="col"> <div class="grid-card-wrapper" data-project-id="mabvit2-model-agnostic-bayesian-vision-transformer" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #C5050C;"> University of Wisconsin-Madison </div> <h3 class="card-title">MABViT2 - Model Agnostic Bayesian Vision Transformer</h3> <p class="card-text small">Novel architecture for vision transformer with uncertainty quantification</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-mabvit2-model-agnostic-bayesian-vision-transformer" style="display: none;"> <div class="modal-header" style="border-color: #C5050C;"> <h2>MABViT2 - Model Agnostic Bayesian Vision Transformer</h2> <div class="modal-org" style="color: #C5050C;"> University of Wisconsin-Madison - September 2023 </div> </div> <div class="modal-description"> <p>Novel architecture for vision transformer with uncertainty quantification</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>Vision Transformers (ViTs) have emerged as powerful models for computer vision tasks but often lack reliable uncertainty quantification. This project addresses this gap by developing MABViT2, a Model Agnostic Bayesian Vision Transformer, enabling uncertainty estimation without architectural modifications.</p> <h1 id="key-contributions">Key Contributions:</h1> <ul> <li>Developed a Bayesian ViT model that quantifies uncertainty without architectural changes</li> <li>Implemented a variational inference approach for parameter estimation</li> <li>Validated performance on benchmark datasets while maintaining competitive accuracy</li> <li>Demonstrated superior out-of-distribution detection compared to deterministic baselines</li> <li>Created a flexible implementation that can be applied to any existing Vision Transformer</li> </ul> <h1 id="technical-details">Technical Details:</h1> <p>The MABViT2 framework uses a Monte Carlo Dropout method in the self-attention mechanism to approximate Bayesian inference. By running multiple forward passes with different dropout masks, the model generates a distribution of predictions that capture epistemic uncertainty. The implementation is compatible with existing ViT architectures like DeiT and ViT-B models.</p> <h1 id="significance">Significance:</h1> <p>This work bridges a critical gap in computer vision by enabling uncertainty quantification in transformer-based models, which is essential for high-stakes applications like medical imaging and autonomous driving. The model-agnostic approach makes it straightforward to apply to existing systems without architectural redesign.</p> </div> </div> </div> </div> <div class="col"> <div class="grid-card-wrapper" data-project-id="vision-language-navigation-with-transformer-architectures" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #C5050C;"> University of Wisconsin-Madison </div> <h3 class="card-title">Vision-Language Navigation with Transformer Architectures</h3> <p class="card-text small">Transformer-based agent for navigating complex environments using natural language instructions</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-vision-language-navigation-with-transformer-architectures" style="display: none;"> <div class="modal-header" style="border-color: #C5050C;"> <h2>Vision-Language Navigation with Transformer Architectures</h2> <div class="modal-org" style="color: #C5050C;"> University of Wisconsin-Madison - June 2023 </div> </div> <div class="modal-description"> <p>Transformer-based agent for navigating complex environments using natural language instructions</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project addresses the challenge of vision-language navigation (VLN), where an agent must navigate to a target location following natural language instructions. The approach uses a transformer-based architecture to integrate visual, linguistic, and spatial information, enabling robust navigation in complex, previously unseen environments.</p> <h1 id="key-contributions">Key Contributions:</h1> <ul> <li>Developed a multi-modal transformer architecture that jointly processes visual and linguistic inputs</li> <li>Implemented a hierarchical planning module that breaks down navigation into macro and micro actions</li> <li>Created a novel attention mechanism that grounds language instructions to visual features</li> <li>Designed a pre-training strategy using a combination of web-scale image-text pairs and navigation data</li> <li>Evaluated the approach on standard VLN benchmarks including R2R, REVERIE, and SOON datasets</li> </ul> <h1 id="technical-implementation">Technical Implementation:</h1> <p>The core architecture consists of:</p> <ol> <li> <p><strong>Visual Encoder</strong>: A vision transformer processes panoramic images at each viewpoint, extracting features at multiple scales.</p> </li> <li> <p><strong>Language Understanding Module</strong>: A language transformer encodes instructions and maintains an attention-based progress monitor.</p> </li> <li> <p><strong>Cross-Modal Reasoning</strong>: A fusion transformer integrates visual and linguistic features, generating a representation that guides navigation decisions.</p> </li> <li> <p><strong>Action Predictor</strong>: A hierarchical decision module that first selects high-level directions and then refines to specific viewpoints.</p> </li> </ol> <p>The model was implemented in PyTorch and trained using a combination of imitation learning and reinforcement learning, with a curriculum that gradually increased the complexity of navigation scenarios.</p> <h1 id="results">Results:</h1> <ul> <li>15% improvement in success rate on the R2R benchmark compared to previous methods</li> <li>12% higher success rate on the REVERIE dataset for object-grounded navigation</li> <li>Effective zero-shot transfer to unseen environments</li> <li>Robust performance with ambiguous and complex language instructions</li> </ul> <p>The project demonstrates the effectiveness of transformer architectures for embodied AI tasks, particularly those requiring multi-modal reasoning and long-horizon planning.</p> </div> </div> </div> </div> <div class="col"> <div class="grid-card-wrapper" data-project-id="robot-action-exploration-using-bayesian-optimization" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #C5050C;"> University of Wisconsin-Madison </div> <h3 class="card-title">Robot Action Exploration using Bayesian Optimization</h3> <p class="card-text small">Novel reinforcement learning approach for efficient robot skill acquisition</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-robot-action-exploration-using-bayesian-optimization" style="display: none;"> <div class="modal-header" style="border-color: #C5050C;"> <h2>Robot Action Exploration using Bayesian Optimization</h2> <div class="modal-org" style="color: #C5050C;"> University of Wisconsin-Madison - May 2023 </div> </div> <div class="modal-description"> <p>Novel reinforcement learning approach for efficient robot skill acquisition</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project addresses the challenge of efficient exploration in robotic manipulation tasks. Traditional reinforcement learning approaches often struggle with the high-dimensional action spaces and sparse rewards common in manipulation tasks. Our approach uses Bayesian optimization to guide exploration in a hierarchical action space, significantly improving learning efficiency.</p> <h1 id="key-contributions">Key Contributions:</h1> <ul> <li>Developed a hierarchical exploration strategy that decomposes complex manipulation tasks into subtasks</li> <li>Implemented a Gaussian Process-based Bayesian optimization framework for efficient action selection</li> <li>Created a directed exploration mechanism based on information gain and expected improvement</li> <li>Designed a task-agnostic representation that generalizes across different manipulation scenarios</li> <li>Evaluated the approach on a range of real-world robotic manipulation tasks</li> </ul> <h1 id="technical-implementation">Technical Implementation:</h1> <p>The framework consists of three main components:</p> <ol> <li> <p><strong>Hierarchical Action Space</strong>: Complex manipulation tasks are represented as sequences of primitive actions organized in a hierarchical structure.</p> </li> <li> <p><strong>Bayesian Optimization</strong>: A Gaussian Process model maintains a belief over the reward function, guiding exploration toward promising regions of the action space.</p> </li> <li> <p><strong>Information-Directed Sampling</strong>: Actions are selected based on a combination of expected reward and information gain, balancing exploration and exploitation.</p> </li> </ol> <p>The system was implemented using PyTorch for the learning components and integrated with ROS for robot control. Experiments were conducted on a 7-DOF robotic arm performing various manipulation tasks.</p> <h1 id="results">Results:</h1> <ul> <li>45% faster skill acquisition compared to standard reinforcement learning approaches</li> <li>Successful learning of complex manipulation tasks with as few as 50 physical trials</li> <li>Effective transfer learning between related tasks</li> <li>Robust performance under varying initial conditions and object properties</li> </ul> <p>The approach demonstrates significant potential for enabling robots to autonomously learn manipulation skills with minimal human supervision, a critical capability for deploying robots in unstructured environments.</p> </div> </div> </div> </div> <div class="col"> <div class="grid-card-wrapper" data-project-id="reinforcement-learning-for-hexapod-robot" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/hexapod.jpg" sizes="200px"></source> <img src="/assets/img/project/hexapod.jpg" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #c5050c;"> University of Wisconsin-Madison </div> <h3 class="card-title">Reinforcement Learning for Hexapod Robot</h3> <p class="card-text small">Applying reinforcement learning algorithms to optimize the locomotion of a six-legged robot</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-reinforcement-learning-for-hexapod-robot" style="display: none;"> <div class="modal-header" style="border-color: #c5050c;"> <h2>Reinforcement Learning for Hexapod Robot</h2> <div class="modal-org" style="color: #c5050c;"> University of Wisconsin-Madison - February 2023 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/hexapod.jpg" sizes="95vw"></source> <img src="/assets/img/project/hexapod.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Applying reinforcement learning algorithms to optimize the locomotion of a six-legged robot</p> <div class="modal-content"> <p>Every project has a beautiful feature showcase page. It’s easy to include images in a flexible 3-column grid format. Make your photos 1/3, 2/3, or full width.</p> <p>To give your project a background in the portfolio page, just add the img tag to the front matter like so:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
layout: page
title: project
description: a project with a background image
img: /assets/img/12.jpg
---
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1.jpg" sizes="95vw"></source> <img src="/assets/img/1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3.jpg" sizes="95vw"></source> <img src="/assets/img/3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Caption photos easily. On the left, a road goes through a tunnel. Middle, leaves artistically fall in a hipster photoshoot. Right, in another hipster photoshoot, a lumberjack grasps a handful of pine needles. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This image can also have a caption. It's like magic. </div> <p>You can also put regular text between your rows of images. Say you wanted to write a little bit about your project before you posted the rest of the images. You describe how you toiled, sweated, <em>bled</em> for your project, and then… you reveal its glory in the next row of images.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6.jpg" sizes="95vw"></source> <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/11.jpg" sizes="95vw"></source> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> You can also have artistically styled 2/3 + 1/3 images, like these. </div> <p>The code is simple. Just wrap your images with <code class="language-plaintext highlighter-rouge">&lt;div class="col-sm"&gt;</code> and place them inside <code class="language-plaintext highlighter-rouge">&lt;div class="row"&gt;</code> (read more about the <a href="https://getbootstrap.com/docs/4.4/layout/grid/" rel="external nofollow noopener" target="_blank">Bootstrap Grid</a> system). To make images responsive, add <code class="language-plaintext highlighter-rouge">img-fluid</code> class to each; for rounded corners and shadows use <code class="language-plaintext highlighter-rouge">rounded</code> and <code class="language-plaintext highlighter-rouge">z-depth-1</code> classes. Here’s the code for the last row of images above:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"row justify-content-sm-center"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-8 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/6.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-4 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/11.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> </div> </div> </div> </div> </div> <a id="nvidia" href=".#nvidia"> <h2 class="category" style="color: #76b900;">NVIDIA</h2> </a> <div class="row row-cols-2 row-cols-md-4"> <div class="col"> <div class="grid-card-wrapper" data-project-id="cuda-optimized-sparse-matrix-operations" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #76b900;"> NVIDIA </div> <h3 class="card-title">CUDA-Optimized Sparse Matrix Operations</h3> <p class="card-text small">High-performance matrix operations for ML applications running on NVIDIA GPUs</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-cuda-optimized-sparse-matrix-operations" style="display: none;"> <div class="modal-header" style="border-color: #76b900;"> <h2>CUDA-Optimized Sparse Matrix Operations</h2> <div class="modal-org" style="color: #76b900;"> NVIDIA - January 2023 </div> </div> <div class="modal-description"> <p>High-performance matrix operations for ML applications running on NVIDIA GPUs</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project addresses the computational bottlenecks in deep learning inference by developing optimized CUDA kernels for sparse matrix operations. While GPUs excel at dense computations, many modern neural networks benefit from sparsity, making specialized sparse kernels critical for performance.</p> <h1 id="key-contributions">Key Contributions:</h1> <ul> <li>Developed custom CUDA kernels for sparse matrix-vector multiplication with format-specific optimizations</li> <li>Implemented block-sparse operations tailored for transformer attention mechanisms</li> <li>Created a pruning-aware convolution operator that dynamically adapts to various sparsity patterns</li> <li>Designed memory-efficient sparse matrix storage formats optimized for GPU memory access patterns</li> <li>Integrated the optimized kernels with popular deep learning frameworks like PyTorch and TensorFlow</li> </ul> <h1 id="technical-details">Technical Details:</h1> <p>The implementation leverages advanced CUDA features including shared memory optimization, warp-level primitives, and thread coarsening to maximize throughput. The kernels support various sparsity patterns (structured, unstructured, and block sparsity) with format-specific optimizations.</p> <p>For transformer models, specialized attention mechanism kernels were developed that exploit the inherent sparsity in attention masks. The convolution operators use pruning awareness to dynamically skip computations for zero weights, significantly improving inference speed.</p> <h1 id="performance-results">Performance Results:</h1> <ul> <li>3.8x speedup for sparse matrix-vector multiplication compared to cuSPARSE</li> <li>2.5x faster inference for transformer models with 80% sparsity</li> <li>65% reduction in memory footprint for large language models</li> <li>Linear scaling across multiple GPU configurations</li> </ul> <p>These optimizations enable significant speedups for inference workloads while maintaining model accuracy, making deployment of large-scale models more cost-effective.</p> </div> </div> </div> </div> <div class="col"> <div class="grid-card-wrapper" data-project-id="gpu-accelerated-physical-simulation-framework" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #76b900;"> NVIDIA </div> <h3 class="card-title">GPU-Accelerated Physical Simulation Framework</h3> <p class="card-text small">Parallel physics simulation platform for robotics and graphics applications</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-gpu-accelerated-physical-simulation-framework" style="display: none;"> <div class="modal-header" style="border-color: #76b900;"> <h2>GPU-Accelerated Physical Simulation Framework</h2> <div class="modal-org" style="color: #76b900;"> NVIDIA - July 2022 </div> </div> <div class="modal-description"> <p>Parallel physics simulation platform for robotics and graphics applications</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project addresses the challenge of performing physically accurate simulations of complex environments in real-time. By leveraging GPU acceleration through CUDA, the framework achieves significant performance improvements while maintaining simulation accuracy, enabling applications in robotics, computer graphics, and VR/AR.</p> <h1 id="key-features">Key Features:</h1> <ul> <li>Unified constraint-based physical simulation supporting rigid bodies, soft bodies, and fluids</li> <li>Highly parallel implementation of collision detection and constraint solving</li> <li>Spatial data structures optimized for GPU execution patterns</li> <li>Stable numerical integration methods suitable for interactive applications</li> <li>API compatibility with common robotics and graphics frameworks</li> </ul> <h1 id="technical-implementation">Technical Implementation:</h1> <p>The core of the framework consists of a parallel constraint solver that processes thousands of constraints simultaneously on the GPU. For collision detection, a hierarchical spatial subdivision approach is used to efficiently cull non-colliding pairs of objects. Both broad-phase and narrow-phase collision detection are implemented as parallel algorithms.</p> <p>The framework uses a position-based dynamics approach for soft body simulation, allowing for stable and efficient simulation of deformable objects. Fluid simulation is implemented using a smooth particle hydrodynamics (SPH) method, with neighbor finding accelerated through GPU-optimized spatial hashing.</p> <h1 id="performance-results">Performance Results:</h1> <ul> <li>50-100x speedup over equivalent CPU implementations for rigid body simulation</li> <li>Real-time performance with up to 100,000 rigid bodies or 1 million particles</li> <li>Stable simulation at large time steps, suitable for interactive applications</li> <li>Efficient scaling across different NVIDIA GPU architectures</li> </ul> <h1 id="applications">Applications:</h1> <p>The framework has been successfully applied to robotic simulation for reinforcement learning, real-time physics for game engines, and interactive visualization for scientific applications. Its performance characteristics make it particularly suitable for applications requiring both accuracy and interactivity, such as virtual prototyping and realistic VR environments.</p> </div> </div> </div> </div> <div class="col"> <div class="grid-card-wrapper" data-project-id="dct-and-idct-hardware-accelerator" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/IDCT.png" sizes="200px"></source> <img src="/assets/img/project/IDCT.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #76b900;"> NVIDIA </div> <h3 class="card-title">DCT and IDCT Hardware Accelerator</h3> <p class="card-text small">Hardware implementation of Discrete Cosine Transform (DCT) and its inverse for signal processing ...</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-dct-and-idct-hardware-accelerator" style="display: none;"> <div class="modal-header" style="border-color: #76b900;"> <h2>DCT and IDCT Hardware Accelerator</h2> <div class="modal-org" style="color: #76b900;"> NVIDIA - May 2022 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/IDCT.png" sizes="95vw"></source> <img src="/assets/img/project/IDCT.png" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Hardware implementation of Discrete Cosine Transform (DCT) and its inverse for signal processing applications</p> <div class="modal-content"> <p>This project implements a hardware accelerator for Discrete Cosine Transform (DCT) and Inverse Discrete Cosine Transform (IDCT) for signal processing and media applications.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/dct.png" sizes="95vw"></source> <img src="/assets/img/project/dct.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="DCT Diagram" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/IDCT.png" sizes="95vw"></source> <img src="/assets/img/project/IDCT.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="IDCT Diagram" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Left: Flow graph of DCT. Right: Flow graph of IDCT. </div> <h1 id="project-overview">Project Overview:</h1> <p>The core of this work is to implement a hardware accelerator for DCT and IDCT, which are crucial in various signal processing and media applications. With the growth of information technology, the need for efficient compression algorithms has become paramount. DCT has been widely used for several decades due to its incredible energy compaction properties. This project focuses on implementing hardware-level DCT and IDCT transforms for energy-efficient encoding and decoding. The implementation is done using Bluespec, a high-level hardware description language.</p> <h1 id="key-features">Key Features:</h1> <ul> <li>Implementation of Fast DCT algorithm</li> <li>Implementation of IDCT algorithm</li> <li>Modular design for 4-point, 8-point, 16-point, and 32-point transforms</li> <li>Use of Butterfly and Hadamard modules for efficient computation</li> <li>Pipelined architecture for higher throughput</li> <li>The project demonstrates the potential for hardware acceleration in signal processing tasks, particularly in the context of media compression and decompression. It provides a foundation for further optimization and integration into larger systems dealing with video and image processing.</li> </ul> </div> </div> </div> </div> <div class="col"> <div class="grid-card-wrapper" data-project-id="hardware-accelerated-computer-vision-library" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #76b900;"> NVIDIA </div> <h3 class="card-title">Hardware-Accelerated Computer Vision Library</h3> <p class="card-text small">Optimized vision algorithms for embedded systems and edge devices</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-hardware-accelerated-computer-vision-library" style="display: none;"> <div class="modal-header" style="border-color: #76b900;"> <h2>Hardware-Accelerated Computer Vision Library</h2> <div class="modal-org" style="color: #76b900;"> NVIDIA - June 2021 </div> </div> <div class="modal-description"> <p>Optimized vision algorithms for embedded systems and edge devices</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project addresses the challenge of deploying computer vision applications on resource-constrained embedded systems and edge devices. By developing hardware-optimized implementations of common vision algorithms and providing a consistent API across different platforms, the library enables efficient vision processing on a wide range of devices.</p> <h1 id="key-features">Key Features:</h1> <ul> <li>Optimized implementations of fundamental vision operations (filtering, feature extraction, optical flow, etc.)</li> <li>Neural network acceleration for deep learning-based vision tasks</li> <li>Hardware-specific optimizations for various platforms (NVIDIA Jetson, Arm processors, DSPs)</li> <li>Automatic selection of optimal implementation based on available hardware</li> <li>Common API across all supported platforms for code portability</li> <li>Comprehensive performance profiling and power monitoring tools</li> <li>Support for both C++ and Python with minimal dependencies</li> </ul> <h1 id="technical-implementation">Technical Implementation:</h1> <p>The library is structured as a layered architecture:</p> <ol> <li> <p><strong>Core API Layer</strong>: Provides a consistent interface for all vision operations, abstracting hardware details from the user.</p> </li> <li> <p><strong>Algorithm Layer</strong>: Implements various vision algorithms with optimizations for numerical stability and accuracy on embedded platforms.</p> </li> <li> <strong>Acceleration Layer</strong>: Contains hardware-specific implementations leveraging various acceleration technologies: <ul> <li>CUDA for NVIDIA GPUs</li> <li>OpenCL for cross-platform GPU acceleration</li> <li>NEON/SVE optimizations for Arm CPUs</li> <li>DSP offloading for supported SoCs</li> <li>Neural accelerator integration (NVDLA, NPU, etc.)</li> </ul> </li> <li> <strong>Platform Layer</strong>: Handles device detection, capability querying, and optimal implementation selection.</li> </ol> <h1 id="performance-results">Performance Results:</h1> <ul> <li>5-20x speedup compared to general-purpose CPU implementations</li> <li>3-8x power efficiency improvement for common vision pipelines</li> <li>Real-time performance for many vision tasks on embedded platforms: <ul> <li>60+ FPS for 1080p image filtering on Jetson Nano</li> <li>30+ FPS for feature detection and tracking on Arm Cortex-A devices</li> <li>15+ FPS for basic neural network inference on low-power microcontrollers</li> </ul> </li> </ul> <h1 id="applications">Applications:</h1> <p>The library has been successfully applied to various edge computing applications:</p> <ul> <li>Smart camera systems for retail analytics</li> <li>Autonomous robot navigation</li> <li>Augmented reality on mobile devices</li> <li>Industrial quality control systems</li> <li>Smart city infrastructure</li> <li>Low-power IoT vision sensors</li> </ul> <p>The project enables developers to leverage computer vision capabilities on constrained devices without requiring expertise in hardware-specific optimization, accelerating the deployment of intelligent edge applications.</p> </div> </div> </div> </div> <div class="col"> <div class="grid-card-wrapper" data-project-id="natural-language-processing-for-clinical-data" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="200px"></source> <img src="/assets/img/5.jpg" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #76b900;"> NVIDIA </div> <h3 class="card-title">Natural Language Processing for Clinical Data</h3> <p class="card-text small">Using NLP techniques to extract insights from medical records</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-natural-language-processing-for-clinical-data" style="display: none;"> <div class="modal-header" style="border-color: #76b900;"> <h2>Natural Language Processing for Clinical Data</h2> <div class="modal-org" style="color: #76b900;"> NVIDIA - March 2021 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Using NLP techniques to extract insights from medical records</p> <div class="modal-content"> <p>Every project has a beautiful feature showcase page. It’s easy to include images in a flexible 3-column grid format. Make your photos 1/3, 2/3, or full width.</p> <p>To give your project a background in the portfolio page, just add the img tag to the front matter like so:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
layout: page
title: project
description: a project with a background image
img: /assets/img/12.jpg
---
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1.jpg" sizes="95vw"></source> <img src="/assets/img/1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3.jpg" sizes="95vw"></source> <img src="/assets/img/3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Caption photos easily. On the left, a road goes through a tunnel. Middle, leaves artistically fall in a hipster photoshoot. Right, in another hipster photoshoot, a lumberjack grasps a handful of pine needles. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This image can also have a caption. It's like magic. </div> <p>You can also put regular text between your rows of images. Say you wanted to write a little bit about your project before you posted the rest of the images. You describe how you toiled, sweated, <em>bled</em> for your project, and then… you reveal its glory in the next row of images.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6.jpg" sizes="95vw"></source> <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/11.jpg" sizes="95vw"></source> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> You can also have artistically styled 2/3 + 1/3 images, like these. </div> <p>The code is simple. Just wrap your images with <code class="language-plaintext highlighter-rouge">&lt;div class="col-sm"&gt;</code> and place them inside <code class="language-plaintext highlighter-rouge">&lt;div class="row"&gt;</code> (read more about the <a href="https://getbootstrap.com/docs/4.4/layout/grid/" rel="external nofollow noopener" target="_blank">Bootstrap Grid</a> system). To make images responsive, add <code class="language-plaintext highlighter-rouge">img-fluid</code> class to each; for rounded corners and shadows use <code class="language-plaintext highlighter-rouge">rounded</code> and <code class="language-plaintext highlighter-rouge">z-depth-1</code> classes. Here’s the code for the last row of images above:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"row justify-content-sm-center"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-8 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/6.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-4 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/11.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> </div> </div> </div> </div> </div> <a id="iit-madras" href=".#iit-madras"> <h2 class="category" style="color: #231f7e;">IIT Madras</h2> </a> <div class="row row-cols-2 row-cols-md-4"> <div class="col"> <div class="grid-card-wrapper" data-project-id="cheetah-soft-robotics-simulator" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #231f7e;"> IIT Madras </div> <h3 class="card-title">Cheetah Soft Robotics Simulator</h3> <p class="card-text small">Simulation platform for soft robots with real-time performance using GPU acceleration</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-cheetah-soft-robotics-simulator" style="display: none;"> <div class="modal-header" style="border-color: #231f7e;"> <h2>Cheetah Soft Robotics Simulator</h2> <div class="modal-org" style="color: #231f7e;"> IIT Madras - December 2021 </div> </div> <div class="modal-description"> <p>Simulation platform for soft robots with real-time performance using GPU acceleration</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project addresses the challenge of efficiently simulating soft and hybrid rigid-soft robots for design and control applications. Inspired by biological systems like cheetahs, which use their flexible spine for enhanced locomotion, the simulator enables exploration of bio-inspired designs that incorporate soft, deformable components alongside traditional rigid elements.</p> <h1 id="key-features">Key Features:</h1> <ul> <li>FEM-based deformation model for accurate simulation of soft materials with varying properties</li> <li>GPU-accelerated parallel solver achieving real-time performance for complex models</li> <li>Unified treatment of rigid and soft body dynamics within a single simulation framework</li> <li>Contact model specifically designed for soft-rigid interactions</li> <li>Open-source implementation with Python and C++ APIs</li> </ul> <h1 id="technical-implementation">Technical Implementation:</h1> <p>The core of the simulator is built on a finite element method (FEM) approach using a corotational formulation for large deformations. To achieve real-time performance, the computational bottleneck of solving large sparse linear systems is addressed through a custom GPU-accelerated preconditioned conjugate gradient solver.</p> <p>The system incorporates a unified constraint-based formulation that handles both soft body deformation and rigid body dynamics, allowing for seamless simulation of hybrid systems. A specialized contact model accounts for the unique challenges of soft material contact, including friction and self-collision.</p> <h1 id="applications">Applications:</h1> <p>The simulator has been applied to several bio-inspired robotic designs, including:</p> <ol> <li> <p><strong>Cheetah-inspired robot</strong>: A quadrupedal robot with a flexible spine, demonstrating how controlled spinal flexibility can enhance running efficiency and maneuverability.</p> </li> <li> <p><strong>Soft grippers</strong>: Simulation of pneumatically actuated soft grippers for delicate object manipulation.</p> </li> <li> <p><strong>Tensegrity robots</strong>: Robots that use a combination of rigid struts and flexible tensile elements for locomotion and adaptation.</p> </li> </ol> <h1 id="impact">Impact:</h1> <p>The simulator enables researchers to explore the design space of soft and hybrid robots more efficiently, testing concepts virtually before physical prototyping. The ability to run simulations in real-time facilitates the development of control algorithms and the application of learning-based approaches to this challenging domain.</p> </div> </div> </div> </div> <div class="col"> <div class="grid-card-wrapper" data-project-id="carry-save-multiplier-design" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/csm.png" sizes="200px"></source> <img src="/assets/img/project/csm.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #d6a64f;"> IIT Madras </div> <h3 class="card-title">Carry Save Multiplier Design</h3> <p class="card-text small">Implementation of an 8x8 carry save multiplier with optimized CMOS design techniques</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-carry-save-multiplier-design" style="display: none;"> <div class="modal-header" style="border-color: #d6a64f;"> <h2>Carry Save Multiplier Design</h2> <div class="modal-org" style="color: #d6a64f;"> IIT Madras - September 2021 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/csm.png" sizes="95vw"></source> <img src="/assets/img/project/csm.png" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Implementation of an 8x8 carry save multiplier with optimized CMOS design techniques</p> <div class="modal-content"> <h1 id="timelapse-of-8-bit-csm">Timelapse of 8-bit CSM</h1> <p>Designed and implemented a compact 8x8 carry save multiplier, leveraging CMOS technology for digital blocks like Inverters, NAND gates, and Full adders, ensuring efficient operation and verification.</p> <p align="center"> <iframe width="560" height="315" src="https://www.youtube.com/embed/wzYCzxJP9SQ?si=eUT2P8DZPsynLZZF" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> </p> </div> </div> </div> </div> <div class="col"> <div class="grid-card-wrapper" data-project-id="custom-compiler-for-mujoco-physics-engine" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #231f7e;"> IIT Madras </div> <h3 class="card-title">Custom Compiler for MuJoCo Physics Engine</h3> <p class="card-text small">Specialized compiler for accelerating physics-based simulation on heterogeneous hardware</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-custom-compiler-for-mujoco-physics-engine" style="display: none;"> <div class="modal-header" style="border-color: #231f7e;"> <h2>Custom Compiler for MuJoCo Physics Engine</h2> <div class="modal-org" style="color: #231f7e;"> IIT Madras - September 2021 </div> </div> <div class="modal-description"> <p>Specialized compiler for accelerating physics-based simulation on heterogeneous hardware</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project addresses the computational bottleneck in physics-based simulation for reinforcement learning and robotics applications. By developing a specialized compiler for MuJoCo physics engine computations, the system achieves significant performance improvements while maintaining simulation accuracy and enabling gradient-based optimization through automatic differentiation.</p> <h1 id="key-contributions">Key Contributions:</h1> <ul> <li>Developed a domain-specific compiler for MuJoCo physics that performs optimizations specific to dynamics simulation</li> <li>Implemented automatic differentiation for the entire simulation pipeline, enabling gradient-based optimization</li> <li>Created a code generator targeting both CPU (with SIMD vectorization) and GPU (CUDA) backends</li> <li>Designed a memory layout optimizer that improves cache locality and reduces memory transfers</li> <li>Integrated the compiler with popular reinforcement learning frameworks like PyTorch and JAX</li> </ul> <h1 id="technical-implementation">Technical Implementation:</h1> <p>The compiler pipeline consists of several stages:</p> <ol> <li> <p><strong>Intermediate Representation</strong>: Physics computations are represented in a domain-specific IR that captures the mathematical structure of dynamics problems.</p> </li> <li> <p><strong>Analysis and Optimization</strong>: The compiler performs graph-based analyses to identify parallelizable computations, redundant calculations, and opportunities for memory optimization.</p> </li> <li> <p><strong>Automatic Differentiation</strong>: The entire simulation pipeline is made differentiable through source code transformation, enabling efficient computation of gradients.</p> </li> <li> <p><strong>Backend Code Generation</strong>: Optimized code is generated for multiple targets including multicore CPUs with SIMD extensions and NVIDIA GPUs via CUDA.</p> </li> </ol> <p>The system supports the full MuJoCo feature set while providing a clean Python API that integrates with machine learning frameworks.</p> <h1 id="performance-results">Performance Results:</h1> <ul> <li>10x average speedup for forward dynamics simulation compared to standard MuJoCo</li> <li>15x faster gradient computation compared to finite-difference methods</li> <li>8x acceleration of reinforcement learning training loops on benchmark tasks</li> <li>Efficient scaling from desktop computers to HPC clusters</li> </ul> <h1 id="applications">Applications:</h1> <p>The compiler has been successfully applied to accelerate reinforcement learning for robotic control, trajectory optimization for legged locomotion, and high-throughput evolutionary algorithms for robot design. The ability to efficiently compute gradients through physics simulations enables new approaches to controller design and system identification problems.</p> </div> </div> </div> </div> <div class="col"> <div class="grid-card-wrapper" data-project-id="autonomous-hexapod-robot" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/hexapod.jpg" sizes="200px"></source> <img src="/assets/img/project/hexapod.jpg" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #231f7e;"> IIT Madras </div> <h3 class="card-title">Autonomous Hexapod Robot</h3> <p class="card-text small">Designed and built a six-legged robot with advanced locomotion capabilities</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-autonomous-hexapod-robot" style="display: none;"> <div class="modal-header" style="border-color: #231f7e;"> <h2>Autonomous Hexapod Robot</h2> <div class="modal-org" style="color: #231f7e;"> IIT Madras - December 2020 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project/hexapod.jpg" sizes="95vw"></source> <img src="/assets/img/project/hexapod.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Designed and built a six-legged robot with advanced locomotion capabilities</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project involved designing and constructing a six-legged robot (hexapod) with autonomous capabilities. The hexapod features a distributed control system architecture where each leg has independent control while a central controller coordinates overall movement patterns and stability.</p> <h1 id="key-features">Key Features:</h1> <ul> <li>Six-legged design with 3 degrees of freedom per leg (18 actuated joints total)</li> <li>Custom-designed PCBs for motor control and power distribution</li> <li>Implemented advanced gait generation algorithms for different terrain types</li> <li>Developed a real-time stability management system using accelerometer and gyroscope data</li> <li>Integrated computer vision for obstacle detection and navigation planning</li> <li>Designed a lightweight but durable chassis using 3D-printed components</li> </ul> <h1 id="technical-implementation">Technical Implementation:</h1> <p>The robot uses a hierarchical control system with an ARM Cortex-M4 microcontroller as the main controller and dedicated controllers for each leg. Communication between controllers happens over a custom real-time protocol. The gait generator implements several locomotion patterns including tripod, wave, and ripple gaits that can be switched dynamically based on terrain.</p> <p>A RaspberryPi handles higher-level functions including computer vision through a Pi Camera module, processing images to detect obstacles and plan navigation paths. The power system features lithium polymer batteries with efficient DC-DC conversion to maximize runtime.</p> <h1 id="applications">Applications:</h1> <p>The hexapod platform demonstrates capabilities relevant to search and rescue operations, exploration of hazardous environments, and as an educational platform for robotics research. Its ability to navigate uneven terrain makes it suitable for applications where wheeled robots would struggle.</p> </div> </div> </div> </div> <div class="col"> <div class="grid-card-wrapper" data-project-id="autonomous-uav-navigation-system" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #231f7e;"> IIT Madras </div> <h3 class="card-title">Autonomous UAV Navigation System</h3> <p class="card-text small">Vision-based navigation system for drones operating in GPS-denied environments</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-autonomous-uav-navigation-system" style="display: none;"> <div class="modal-header" style="border-color: #231f7e;"> <h2>Autonomous UAV Navigation System</h2> <div class="modal-org" style="color: #231f7e;"> IIT Madras - August 2020 </div> </div> <div class="modal-description"> <p>Vision-based navigation system for drones operating in GPS-denied environments</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project addresses the challenge of enabling autonomous UAV operation in environments where GPS signals are unavailable or unreliable. By relying solely on onboard sensing and computing, the system provides robust navigation capabilities for applications including search and rescue, infrastructure inspection, and indoor operations.</p> <h1 id="key-features">Key Features:</h1> <ul> <li>Visual-inertial odometry for accurate state estimation without GPS</li> <li>Real-time 3D mapping and simultaneous localization (SLAM)</li> <li>Learning-based obstacle detection and avoidance</li> <li>Path planning with dynamic obstacle handling</li> <li>Fault-tolerant control system with emergency recovery modes</li> <li>Lightweight implementation suitable for deployment on commercial drones</li> <li>Development of a custom simulation environment for testing and validation</li> </ul> <h1 id="technical-implementation">Technical Implementation:</h1> <p>The system consists of four main components:</p> <ol> <li> <p><strong>Perception</strong>: A visual-inertial odometry pipeline fuses data from stereo cameras and an IMU to estimate the drone’s position and orientation. This is complemented by a lightweight SLAM system that builds and maintains a 3D map of the environment.</p> </li> <li> <p><strong>Obstacle Avoidance</strong>: A deep learning-based approach detects obstacles from camera images, while a secondary system uses depth information for obstacle verification. The combined system provides reliable obstacle detection even in challenging lighting conditions.</p> </li> <li> <p><strong>Planning</strong>: A hierarchical planning system combines global path planning using a topological map with local trajectory optimization that accounts for dynamics constraints and obstacle avoidance.</p> </li> <li> <p><strong>Control</strong>: A robust control system translates planned trajectories into motor commands, with adaptive gains to handle different flight conditions and failure modes.</p> </li> </ol> <p>The entire system runs on an NVIDIA Jetson Xavier NX onboard computer, with a custom software stack developed using ROS and optimized for real-time performance.</p> <h1 id="applications-and-results">Applications and Results:</h1> <p>The system has been successfully deployed in several applications:</p> <ul> <li> <strong>Search and Rescue</strong>: Autonomous exploration of disaster sites with detection of victims using thermal imaging</li> <li> <strong>Infrastructure Inspection</strong>: Automated inspection of bridges and buildings with detailed 3D reconstruction</li> <li> <strong>Warehouse Inventory</strong>: Indoor navigation for inventory tracking and management</li> </ul> <p>Performance metrics demonstrate:</p> <ul> <li>Localization accuracy of ±5cm in controlled environments</li> <li>Obstacle detection range of up to 10m with 95% accuracy</li> <li>Successful navigation through complex environments with doorways and corridors</li> <li>Flight endurance of 15 minutes with full autonomy stack active</li> </ul> </div> </div> </div> </div> <div class="col"> <div class="grid-card-wrapper" data-project-id="computer-vision-for-autonomous-systems" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1.jpg" sizes="200px"></source> <img src="/assets/img/1.jpg" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #d6a64f;"> IIT Madras </div> <h3 class="card-title">Computer Vision for Autonomous Systems</h3> <p class="card-text small">Developing robust vision systems for self-driving vehicles</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-computer-vision-for-autonomous-systems" style="display: none;"> <div class="modal-header" style="border-color: #d6a64f;"> <h2>Computer Vision for Autonomous Systems</h2> <div class="modal-org" style="color: #d6a64f;"> IIT Madras - July 2020 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1.jpg" sizes="95vw"></source> <img src="/assets/img/1.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Developing robust vision systems for self-driving vehicles</p> <div class="modal-content"> <p>Every project has a beautiful feature showcase page. It’s easy to include images in a flexible 3-column grid format. Make your photos 1/3, 2/3, or full width.</p> <p>To give your project a background in the portfolio page, just add the img tag to the front matter like so:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
layout: page
title: project
description: a project with a background image
img: /assets/img/12.jpg
---
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1.jpg" sizes="95vw"></source> <img src="/assets/img/1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3.jpg" sizes="95vw"></source> <img src="/assets/img/3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Caption photos easily. On the left, a road goes through a tunnel. Middle, leaves artistically fall in a hipster photoshoot. Right, in another hipster photoshoot, a lumberjack grasps a handful of pine needles. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This image can also have a caption. It's like magic. </div> <p>You can also put regular text between your rows of images. Say you wanted to write a little bit about your project before you posted the rest of the images. You describe how you toiled, sweated, <em>bled</em> for your project, and then… you reveal its glory in the next row of images.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6.jpg" sizes="95vw"></source> <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/11.jpg" sizes="95vw"></source> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> You can also have artistically styled 2/3 + 1/3 images, like these. </div> <p>The code is simple. Just wrap your images with <code class="language-plaintext highlighter-rouge">&lt;div class="col-sm"&gt;</code> and place them inside <code class="language-plaintext highlighter-rouge">&lt;div class="row"&gt;</code> (read more about the <a href="https://getbootstrap.com/docs/4.4/layout/grid/" rel="external nofollow noopener" target="_blank">Bootstrap Grid</a> system). To make images responsive, add <code class="language-plaintext highlighter-rouge">img-fluid</code> class to each; for rounded corners and shadows use <code class="language-plaintext highlighter-rouge">rounded</code> and <code class="language-plaintext highlighter-rouge">z-depth-1</code> classes. Here’s the code for the last row of images above:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"row justify-content-sm-center"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-8 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/6.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-4 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/11.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> </div> </div> </div> </div> <div class="col"> <div class="grid-card-wrapper" data-project-id="ai-powered-gta-v-mod-for-autonomous-driving-research" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #231f7e;"> IIT Madras </div> <h3 class="card-title">AI-Powered GTA V Mod for Autonomous Driving Research</h3> <p class="card-text small">Open-source platform for reinforcement learning and computer vision in simulated urban environments</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-ai-powered-gta-v-mod-for-autonomous-driving-research" style="display: none;"> <div class="modal-header" style="border-color: #231f7e;"> <h2>AI-Powered GTA V Mod for Autonomous Driving Research</h2> <div class="modal-org" style="color: #231f7e;"> IIT Madras - May 2020 </div> </div> <div class="modal-description"> <p>Open-source platform for reinforcement learning and computer vision in simulated urban environments</p> <div class="modal-content"> <h1 id="project-overview">Project Overview:</h1> <p>This project addresses the challenge of developing and testing autonomous driving systems by creating a high-fidelity simulation environment based on Grand Theft Auto V. By leveraging the game’s photorealistic graphics, complex physics, and diverse urban environments, the platform enables research on perception, decision-making, and control algorithms for autonomous vehicles.</p> <h1 id="key-features">Key Features:</h1> <ul> <li>Realistic sensor simulation including cameras, LiDAR, radar, and ultrasonic sensors</li> <li>Full access to ground truth data including semantic segmentation, depth maps, and object positions</li> <li>Programmable traffic scenarios with customizable vehicle behaviors</li> <li>Weather and lighting condition control for testing robustness</li> <li>Python API for integration with popular machine learning frameworks</li> <li>Data collection pipeline for creating training datasets</li> <li>Benchmarking suite for comparing different autonomous driving approaches</li> </ul> <h1 id="technical-implementation">Technical Implementation:</h1> <p>The system consists of three main components:</p> <ol> <li> <p><strong>Game Integration</strong>: A native plugin that interfaces with the game engine to extract rendering information, control vehicles, and modify the game environment.</p> </li> <li> <p><strong>Sensor Simulation</strong>: A physics-based simulation layer that generates realistic sensor outputs based on the game state, including camera images with proper distortion, LiDAR point clouds with appropriate noise characteristics, and radar returns.</p> </li> <li> <p><strong>Research Interface</strong>: A Python API that provides access to simulation controls, sensor data, and ground truth information, with built-in support for reinforcement learning environments and computer vision datasets.</p> </li> </ol> <p>The modification was implemented using a combination of C++ for the game integration and Python for the research interface, with optimized data transfer between the two.</p> <h1 id="applications">Applications:</h1> <p>The platform has been used for various autonomous driving research applications:</p> <ul> <li>Training and evaluating perception algorithms in diverse and challenging conditions</li> <li>Developing reinforcement learning agents for urban driving scenarios</li> <li>Benchmarking decision-making algorithms for complex traffic situations</li> <li>Generating synthetic training data for machine learning models</li> <li>Testing edge cases and rare events that are difficult to encounter in real-world testing</li> </ul> <h1 id="impact">Impact:</h1> <p>By providing an accessible, high-fidelity simulation environment, this project helps accelerate autonomous driving research without the high costs and safety concerns associated with real-world testing. The open-source nature of the platform has enabled researchers from various institutions to contribute and build upon the framework.</p> </div> </div> </div> </div> <div class="col"> <div class="grid-card-wrapper" data-project-id="early-ai-research-project" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/8.jpg" sizes="200px"></source> <img src="/assets/img/8.jpg" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #d6a64f;"> IIT Madras </div> <h3 class="card-title">Early AI Research Project</h3> <p class="card-text small">Early exploration of neural networks for pattern recognition</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-early-ai-research-project" style="display: none;"> <div class="modal-header" style="border-color: #d6a64f;"> <h2>Early AI Research Project</h2> <div class="modal-org" style="color: #d6a64f;"> IIT Madras - February 2020 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/8.jpg" sizes="95vw"></source> <img src="/assets/img/8.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Early exploration of neural networks for pattern recognition</p> <div class="modal-content"> <p>Every project has a beautiful feature showcase page. It’s easy to include images in a flexible 3-column grid format. Make your photos 1/3, 2/3, or full width.</p> <p>To give your project a background in the portfolio page, just add the img tag to the front matter like so:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
layout: page
title: project
description: a project with a background image
img: /assets/img/12.jpg
---
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1.jpg" sizes="95vw"></source> <img src="/assets/img/1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3.jpg" sizes="95vw"></source> <img src="/assets/img/3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Caption photos easily. On the left, a road goes through a tunnel. Middle, leaves artistically fall in a hipster photoshoot. Right, in another hipster photoshoot, a lumberjack grasps a handful of pine needles. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This image can also have a caption. It's like magic. </div> <p>You can also put regular text between your rows of images. Say you wanted to write a little bit about your project before you posted the rest of the images. You describe how you toiled, sweated, <em>bled</em> for your project, and then… you reveal its glory in the next row of images.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6.jpg" sizes="95vw"></source> <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/11.jpg" sizes="95vw"></source> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> You can also have artistically styled 2/3 + 1/3 images, like these. </div> <p>The code is simple. Just wrap your images with <code class="language-plaintext highlighter-rouge">&lt;div class="col-sm"&gt;</code> and place them inside <code class="language-plaintext highlighter-rouge">&lt;div class="row"&gt;</code> (read more about the <a href="https://getbootstrap.com/docs/4.4/layout/grid/" rel="external nofollow noopener" target="_blank">Bootstrap Grid</a> system). To make images responsive, add <code class="language-plaintext highlighter-rouge">img-fluid</code> class to each; for rounded corners and shadows use <code class="language-plaintext highlighter-rouge">rounded</code> and <code class="language-plaintext highlighter-rouge">z-depth-1</code> classes. Here’s the code for the last row of images above:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"row justify-content-sm-center"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-8 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/6.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-4 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/11.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> </div> </div> </div> </div> </div> <a id="high-school" href=".#high-school"> <h2 class="category" style="color: #3fdcbf;">High School</h2> </a> <div class="row row-cols-2 row-cols-md-4"> <div class="col"> <div class="grid-card-wrapper" data-project-id="high-school-project" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/4.jpg" sizes="200px"></source> <img src="/assets/img/4.jpg" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #3fdcbf;"> High School </div> <h3 class="card-title">High School Project</h3> <p class="card-text small">Project from pre-college years</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-high-school-project" style="display: none;"> <div class="modal-header" style="border-color: #3fdcbf;"> <h2>High School Project</h2> <div class="modal-org" style="color: #3fdcbf;"> High School - November 2019 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/4.jpg" sizes="95vw"></source> <img src="/assets/img/4.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Project from pre-college years</p> <div class="modal-content"> <p>Every project has a beautiful feature showcase page. It’s easy to include images in a flexible 3-column grid format. Make your photos 1/3, 2/3, or full width.</p> <p>To give your project a background in the portfolio page, just add the img tag to the front matter like so:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
layout: page
title: project
description: a project with a background image
img: /assets/img/12.jpg
---
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1.jpg" sizes="95vw"></source> <img src="/assets/img/1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3.jpg" sizes="95vw"></source> <img src="/assets/img/3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Caption photos easily. On the left, a road goes through a tunnel. Middle, leaves artistically fall in a hipster photoshoot. Right, in another hipster photoshoot, a lumberjack grasps a handful of pine needles. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This image can also have a caption. It's like magic. </div> <p>You can also put regular text between your rows of images, even citations (missing reference). Say you wanted to write a bit about your project before you posted the rest of the images. You describe how you toiled, sweated, <em>bled</em> for your project, and then… you reveal its glory in the next row of images.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6.jpg" sizes="95vw"></source> <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/11.jpg" sizes="95vw"></source> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> You can also have artistically styled 2/3 + 1/3 images, like these. </div> <p>The code is simple. Just wrap your images with <code class="language-plaintext highlighter-rouge">&lt;div class="col-sm"&gt;</code> and place them inside <code class="language-plaintext highlighter-rouge">&lt;div class="row"&gt;</code> (read more about the <a href="https://getbootstrap.com/docs/4.4/layout/grid/" rel="external nofollow noopener" target="_blank">Bootstrap Grid</a> system). To make images responsive, add <code class="language-plaintext highlighter-rouge">img-fluid</code> class to each; for rounded corners and shadows use <code class="language-plaintext highlighter-rouge">rounded</code> and <code class="language-plaintext highlighter-rouge">z-depth-1</code> classes. Here’s the code for the last row of images above:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"row justify-content-sm-center"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-8 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/6.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-4 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/11.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> </div> </div> </div> </div> <div class="col"> <div class="grid-card-wrapper" data-project-id="robotics-competition-project" onclick="openProjectModal(this)"> <div class="card h-100 hoverable grid-card"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6.jpg" sizes="200px"></source> <img src="/assets/img/6.jpg" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body py-2 px-3"> <div class="card-org" style="color: #3fdcbf;"> High School </div> <h3 class="card-title">Robotics Competition Project</h3> <p class="card-text small">Award-winning high school robotics project</p> <div class="row ml-1 mr-1 p-0"> </div> </div> </div> </div> <div id="modal-content-robotics-competition-project" style="display: none;"> <div class="modal-header" style="border-color: #3fdcbf;"> <h2>Robotics Competition Project</h2> <div class="modal-org" style="color: #3fdcbf;"> High School - May 2018 </div> </div> <div class="modal-img"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6.jpg" sizes="95vw"></source> <img src="/assets/img/6.jpg" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="modal-description"> <p>Award-winning high school robotics project</p> <div class="modal-content"> <p>Every project has a beautiful feature showcase page. It’s easy to include images in a flexible 3-column grid format. Make your photos 1/3, 2/3, or full width.</p> <p>To give your project a background in the portfolio page, just add the img tag to the front matter like so:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
layout: page
title: project
description: a project with a background image
img: /assets/img/12.jpg
---
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1.jpg" sizes="95vw"></source> <img src="/assets/img/1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3.jpg" sizes="95vw"></source> <img src="/assets/img/3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Caption photos easily. On the left, a road goes through a tunnel. Middle, leaves artistically fall in a hipster photoshoot. Right, in another hipster photoshoot, a lumberjack grasps a handful of pine needles. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5.jpg" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This image can also have a caption. It's like magic. </div> <p>You can also put regular text between your rows of images. Say you wanted to write a little bit about your project before you posted the rest of the images. You describe how you toiled, sweated, <em>bled</em> for your project, and then… you reveal its glory in the next row of images.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6.jpg" sizes="95vw"></source> <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/11.jpg" sizes="95vw"></source> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> You can also have artistically styled 2/3 + 1/3 images, like these. </div> <p>The code is simple. Just wrap your images with <code class="language-plaintext highlighter-rouge">&lt;div class="col-sm"&gt;</code> and place them inside <code class="language-plaintext highlighter-rouge">&lt;div class="row"&gt;</code> (read more about the <a href="https://getbootstrap.com/docs/4.4/layout/grid/" rel="external nofollow noopener" target="_blank">Bootstrap Grid</a> system). To make images responsive, add <code class="language-plaintext highlighter-rouge">img-fluid</code> class to each; for rounded corners and shadows use <code class="language-plaintext highlighter-rouge">rounded</code> and <code class="language-plaintext highlighter-rouge">z-depth-1</code> classes. Here’s the code for the last row of images above:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"row justify-content-sm-center"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-8 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/6.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-4 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/11.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> </div> </div> </div> </div> </div> </div> </div> <div class="project-modal-backdrop" id="project-modal-backdrop" onclick="closeProjectModalFromBackdrop(event)"> <div class="project-modal" id="project-modal"> <div id="modal-content-container"></div> </div> </div> <script>function openProjectModal(e){const t=e.getAttribute("data-project-id"),o=document.getElementById(`modal-content-${t}`),n=document.getElementById("modal-content-container"),l=document.getElementById("project-modal"),i=document.getElementById("project-modal-backdrop");if(o&&n){l&&(l.scrollTop=0,setTimeout(()=>{l.scrollTop=0},10));const e=/<div class="modal-header"([^>]*)>/,t='<div class="modal-header"$1><button class="modal-close" onclick="closeProjectModal()">\xd7</button>',c=o.innerHTML.replace(e,t);n.innerHTML=c,i.style.display="flex",setTimeout(()=>{i.classList.add("visible"),l.classList.add("visible")},10),document.body.style.overflow="hidden",document.addEventListener("keydown",handleModalKeypress)}}function closeProjectModal(){const e=document.getElementById("project-modal"),t=document.getElementById("project-modal-backdrop");e.classList.remove("visible"),t.classList.remove("visible"),setTimeout(()=>{t.style.display="none",document.getElementById("modal-content-container").innerHTML=""},300),document.body.style.overflow="",document.removeEventListener("keydown",handleModalKeypress)}function handleModalKeypress(e){"Escape"===e.key&&closeProjectModal()}function closeProjectModalFromBackdrop(e){"project-modal-backdrop"===e.target.id&&closeProjectModal()}document.addEventListener("DOMContentLoaded",function(){function e(e){e!==d&&(d=e,document.querySelectorAll(`.switcher-btn[data-view="${e}"]`).forEach(e=>{const t=e.closest(".switcher-container"),o=t.querySelectorAll(".switcher-btn"),n=t.querySelector(".switcher-slider");o.forEach(e=>e.classList.remove("active")),e.classList.add("active");const l=Array.from(o).indexOf(e),i=100/o.length;n.style.left=`calc(${i*l}% + 6px)`,n.style.width=`calc(${i}% - 12px)`}),"timeline"===e?(l.style.display="",i.style.display="none",window.dispatchEvent&&window.dispatchEvent(new Event("load"))):"grid"===e&&(l.style.display="none",i.style.display=""))}function t(){return Array.from(document.querySelectorAll(".timeline-entry")).filter(e=>"none"!==e.style.display)}function o(){return Array.from(document.querySelectorAll("#grid-view a[id]")).filter(e=>"none"!==window.getComputedStyle(e).display)}function n(e){if("timeline"===d){if(e<0&&(e=0),e>=(a=t()).length&&(e=a.length-1),a.length>0){s=e;const t=a[e],o=t.getBoundingClientRect(),n=window.innerHeight,l=t.querySelector(".timeline-dot");if(l){const e=l.getBoundingClientRect(),t=-10,o=window.scrollY+e.top-n/2+t;window.scrollTo({top:o,behavior:"smooth"})}else{const e=window.scrollY+o.top+o.height/2-n/2;window.scrollTo({top:e,behavior:"smooth"})}a.forEach(e=>e.classList.remove("active")),t.classList.add("active")}}else if(e<0&&(e=0),e>=(a=o()).length&&(e=a.length-1),a.length>0){s=e;const t=a[e];t.scrollIntoView({behavior:"smooth",block:"center"}),document.querySelectorAll("#grid-view .card").forEach(e=>{e.style.transform="scale(1)",e.style.boxShadow=""});const o=t.querySelector(".card");o&&(o.style.transform="scale(1.02)",o.style.boxShadow="0 10px 25px rgba(0, 0, 0, 0.15)")}}const l=document.getElementById("timeline-view"),i=document.getElementById("grid-view"),c=document.querySelectorAll(".switcher-btn"),r=document.querySelectorAll(".switcher-slider");let d="timeline",s=0,a=[];const m=0;r.forEach(e=>{const t=50;e.style.left=`calc(${t*m}% + 6px)`,e.style.width=`calc(${t}% - 12px)`}),window.addEventListener("scroll",function(){if("timeline"===d){const e=window.innerHeight/2,o=t();let n=null,l=Infinity,i=0;o.forEach((t,o)=>{const c=t.getBoundingClientRect(),r=c.top+c.height/2,d=Math.abs(e-r);d<l&&(l=d,n=t,i=o)}),n&&(s=i)}}),setTimeout(()=>{(a="timeline"===d?t():o()).length>0&&"timeline"===d&&n(0)},500),document.addEventListener("keydown",function(l){const i=l.key.toLowerCase(),c=document.getElementById("project-modal-backdrop");if((!c||"flex"!==c.style.display)&&(["arrowup","arrowdown","arrowleft","arrowright","w","a","s","d"].includes(i)&&l.preventDefault(),"arrowleft"===i||"a"===i?(e("timeline"),setTimeout(()=>n(0),300)):"arrowright"!==i&&"d"!==i||(e("grid"),setTimeout(()=>n(0),300)),"arrowup"===i||"w"===i?n(s-1):"arrowdown"!==i&&"s"!==i||n(s+1),"enter"===i))if("timeline"===d){if((a=t()).length>0&&s>=0&&s<a.length){const e=a[s];e&&openProjectModal(e.querySelector(".timeline-card-link"))}}else if((a=o()).length>0&&s>=0&&s<a.length){const e=a[s];e&&openProjectModal(e)}}),c.forEach(t=>{t.addEventListener("click",function(){e(this.getAttribute("data-view"))})})});</script> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Aswinkumar . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: March 02, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"post-hackaday-superconference-2024-caltech-la-gta-v",title:"Hackaday Superconference 2024 - Caltech - LA / GTA V",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/LA-Trip/"}},{id:"post-getting-started-with-mujoco-part-2",title:"Getting Started with MuJoCo - Part 2",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2020/mujoco-part-1/"}},{id:"post-getting-started-with-mujoco",title:"Getting Started with MuJoCo",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2020/mujoco-part-0/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-high-school-project",title:"High School Project",description:"Project from pre-college years",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-early-ai-research-project",title:"Early AI Research Project",description:"Early exploration of neural networks for pattern recognition",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-ai-powered-gta-v-mod-for-autonomous-driving-research",title:"AI-Powered GTA V Mod for Autonomous Driving Research",description:"Open-source platform for reinforcement learning and computer vision in simulated urban environments",section:"Projects",handler:()=>{window.location.href="/projects/18_project/"}},{id:"projects-computer-vision-for-autonomous-systems",title:"Computer Vision for Autonomous Systems",description:"Developing robust vision systems for self-driving vehicles",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-autonomous-uav-navigation-system",title:"Autonomous UAV Navigation System",description:"Vision-based navigation system for drones operating in GPS-denied environments",section:"Projects",handler:()=>{window.location.href="/projects/20_project/"}},{id:"projects-autonomous-hexapod-robot",title:"Autonomous Hexapod Robot",description:"Designed and built a six-legged robot with advanced locomotion capabilities",section:"Projects",handler:()=>{window.location.href="/projects/11_project/"}},{id:"projects-natural-language-processing-for-clinical-data",title:"Natural Language Processing for Clinical Data",description:"Using NLP techniques to extract insights from medical records",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-hardware-accelerated-computer-vision-library",title:"Hardware-Accelerated Computer Vision Library",description:"Optimized vision algorithms for embedded systems and edge devices",section:"Projects",handler:()=>{window.location.href="/projects/19_project/"}},{id:"projects-custom-compiler-for-mujoco-physics-engine",title:"Custom Compiler for MuJoCo Physics Engine",description:"Specialized compiler for accelerating physics-based simulation on heterogeneous hardware",section:"Projects",handler:()=>{window.location.href="/projects/16_project/"}},{id:"projects-carry-save-multiplier-design",title:"Carry Save Multiplier Design",description:"Implementation of an 8x8 carry save multiplier with optimized CMOS design techniques",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-cheetah-soft-robotics-simulator",title:"Cheetah Soft Robotics Simulator",description:"Simulation platform for soft robots with real-time performance using GPU acceleration",section:"Projects",handler:()=>{window.location.href="/projects/17_project/"}},{id:"projects-dct-and-idct-hardware-accelerator",title:"DCT and IDCT Hardware Accelerator",description:"Hardware implementation of Discrete Cosine Transform (DCT) and its inverse for signal processing applications",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-gpu-accelerated-physical-simulation-framework",title:"GPU-Accelerated Physical Simulation Framework",description:"Parallel physics simulation platform for robotics and graphics applications",section:"Projects",handler:()=>{window.location.href="/projects/14_project/"}},{id:"projects-cuda-optimized-sparse-matrix-operations",title:"CUDA-Optimized Sparse Matrix Operations",description:"High-performance matrix operations for ML applications running on NVIDIA GPUs",section:"Projects",handler:()=>{window.location.href="/projects/12_project/"}},{id:"projects-reinforcement-learning-for-hexapod-robot",title:"Reinforcement Learning for Hexapod Robot",description:"Applying reinforcement learning algorithms to optimize the locomotion of a six-legged robot",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-robot-action-exploration-using-bayesian-optimization",title:"Robot Action Exploration using Bayesian Optimization",description:"Novel reinforcement learning approach for efficient robot skill acquisition",section:"Projects",handler:()=>{window.location.href="/projects/13_project/"}},{id:"projects-vision-language-navigation-with-transformer-architectures",title:"Vision-Language Navigation with Transformer Architectures",description:"Transformer-based agent for navigating complex environments using natural language instructions",section:"Projects",handler:()=>{window.location.href="/projects/15_project/"}},{id:"projects-mabvit2-model-agnostic-bayesian-vision-transformer",title:"MABViT2 - Model Agnostic Bayesian Vision Transformer",description:"Novel architecture for vision transformer with uncertainty quantification",section:"Projects",handler:()=>{window.location.href="/projects/10_project/"}},{id:"projects-wisconsin-ml-project",title:"Wisconsin ML Project",description:"Machine learning research conducted at UW-Madison",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-robotics-competition-project",title:"Robotics Competition Project",description:"Award-winning high school robotics project",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%72%61%6D%6B%75%6D%61%72%34@%77%69%73%63.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=zIFaYCsAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/aswinkumar1999","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/aswinkumar99","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>